{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Reshape, Lambda, Flatten, Activation, Conv2D, Conv2DTranspose, Dense, Input, Subtract, Add, Multiply\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Sequential, Model\n",
    "from keras.engine.network import Network\n",
    "from keras.optimizers import Adadelta\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_generator(input_shape=(256, 256, 3)):\n",
    "    in_layer = Input(shape=input_shape)\n",
    "\n",
    "    model = Conv2D(64, kernel_size=5, strides=1, padding='same',\n",
    "                     dilation_rate=(1, 1))(in_layer)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2D(128, kernel_size=3, strides=2,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(128, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2D(256, kernel_size=3, strides=2,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(2, 2))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(4, 4))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(8, 8))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(16, 16))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2DTranspose(128, kernel_size=4, strides=2,\n",
    "                              padding='same')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(128, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2DTranspose(64, kernel_size=4, strides=2,\n",
    "                              padding='same')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(32, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2D(3, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('sigmoid')(model)\n",
    "    model_gen = Model(inputs=in_layer, outputs=model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_generator2(input_shape=(256, 256, 3)):\n",
    "    \n",
    "    org_img = Input(shape=input_shape)\n",
    "    mask = Input(shape=(input_shape[0], input_shape[1], 1))\n",
    "\n",
    "    # grab the inverse mask, that only shows the masked areas\n",
    "    # 1 - mask\n",
    "    model = Subtract()([org_img, mask])\n",
    "    \n",
    "    # which outputs the erased_image as input\n",
    "    # org_img * (1 - mask)\n",
    "    model = Multiply()([org_img, model])\n",
    "    \n",
    "    model = Conv2D(64, kernel_size=5, strides=1, padding='same',\n",
    "                     dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2D(128, kernel_size=3, strides=2,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(128, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2D(256, kernel_size=3, strides=2,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(2, 2))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(4, 4))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(8, 8))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(16, 16))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2DTranspose(128, kernel_size=4, strides=2,\n",
    "                              padding='same')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(128, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2DTranspose(64, kernel_size=4, strides=2,\n",
    "                              padding='same')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(32, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2D(3, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('sigmoid')(model)\n",
    "    model_gen = Model(inputs=[org_img, mask], outputs=model)\n",
    "    print(model_gen.summary())\n",
    "    return model_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_discriminator(global_shape=(256, 256, 3), local_shape=(128, 128, 3)):\n",
    "    def crop_image(img, crop):\n",
    "        return tf.image.crop_to_bounding_box(img,\n",
    "                                             crop[1],\n",
    "                                             crop[0],\n",
    "                                             crop[3] - crop[1],\n",
    "                                             crop[2] - crop[0])\n",
    "\n",
    "    in_pts = Input(shape=(4,), dtype='int32')\n",
    "    cropping = Lambda(lambda x: K.map_fn(lambda y: crop_image(y[0], y[1]), elems=x, dtype=tf.float32),\n",
    "                      output_shape=local_shape)\n",
    "    g_img = Input(shape=global_shape)\n",
    "    l_img = cropping([g_img, in_pts])\n",
    "\n",
    "    # Local Discriminator\n",
    "    x_l = Conv2D(64, kernel_size=5, strides=2, padding='same')(l_img)\n",
    "    x_l = BatchNormalization()(x_l)\n",
    "    x_l = Activation('relu')(x_l)\n",
    "    x_l = Conv2D(128, kernel_size=5, strides=2, padding='same')(x_l)\n",
    "    x_l = BatchNormalization()(x_l)\n",
    "    x_l = Activation('relu')(x_l)\n",
    "    x_l = Conv2D(256, kernel_size=5, strides=2, padding='same')(x_l)\n",
    "    x_l = BatchNormalization()(x_l)\n",
    "    x_l = Activation('relu')(x_l)\n",
    "    x_l = Conv2D(512, kernel_size=5, strides=2, padding='same')(x_l)\n",
    "    x_l = BatchNormalization()(x_l)\n",
    "    x_l = Activation('relu')(x_l)\n",
    "    x_l = Conv2D(512, kernel_size=5, strides=2, padding='same')(x_l)\n",
    "    x_l = BatchNormalization()(x_l)\n",
    "    x_l = Activation('relu')(x_l)\n",
    "    x_l = Flatten()(x_l)\n",
    "    x_l = Dense(1024, activation='relu')(x_l)\n",
    "\n",
    "    # Global Discriminator\n",
    "    x_g = Conv2D(64, kernel_size=5, strides=2, padding='same')(g_img)\n",
    "    x_g = BatchNormalization()(x_g)\n",
    "    x_g = Activation('relu')(x_g)\n",
    "    x_g = Conv2D(128, kernel_size=5, strides=2, padding='same')(x_g)\n",
    "    x_g = BatchNormalization()(x_g)\n",
    "    x_g = Activation('relu')(x_g)\n",
    "    x_g = Conv2D(256, kernel_size=5, strides=2, padding='same')(x_g)\n",
    "    x_g = BatchNormalization()(x_g)\n",
    "    x_g = Activation('relu')(x_g)\n",
    "    x_g = Conv2D(512, kernel_size=5, strides=2, padding='same')(x_g)\n",
    "    x_g = BatchNormalization()(x_g)\n",
    "    x_g = Activation('relu')(x_g)\n",
    "    x_g = Conv2D(512, kernel_size=5, strides=2, padding='same')(x_g)\n",
    "    x_g = BatchNormalization()(x_g)\n",
    "    x_g = Activation('relu')(x_g)\n",
    "    x_g = Conv2D(512, kernel_size=5, strides=2, padding='same')(x_g)\n",
    "    x_g = BatchNormalization()(x_g)\n",
    "    x_g = Activation('relu')(x_g)\n",
    "    x_g = Flatten()(x_g)\n",
    "    x_g = Dense(1024, activation='relu')(x_g)\n",
    "\n",
    "    x = Concatenate(axis=1)([x_l, x_g])\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    return Model(inputs=[g_img, in_pts], outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_models():\n",
    "    from keras.utils import plot_model\n",
    "    generator = model_generator()\n",
    "    generator.summary()\n",
    "    plot_model(generator, to_file='summaries/generator.png', show_shapes=True)\n",
    "    discriminator = model_discriminator()\n",
    "    discriminator.summary()\n",
    "    plot_model(discriminator, to_file='summaries/discriminator.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'activation_85/Sigmoid:0' shape=(?, ?, ?, 3) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gx1 = model_generator()\n",
    "gx1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'multiply_52/mul:0' shape=(?, 256, 256, 3) dtype=float32>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Concatenate\n",
    "\n",
    "input_shape=(256, 256, 3)\n",
    "org_img = Input(shape=input_shape)\n",
    "mask = Input(shape=(input_shape[0], input_shape[1], 1))\n",
    "\n",
    "# grab the inverse mask, that only shows the masked areas\n",
    "# 1 - mask\n",
    "premodel = Subtract()([org_img, mask])\n",
    "    \n",
    "# which outputs the erased_image as input\n",
    "# org_img * (1 - mask)\n",
    "premodel = Multiply()([org_img, premodel])\n",
    "\n",
    "# view our net\n",
    "# imitation_net = model_generator(input_shape)(premodel)\n",
    "\n",
    "premodel\n",
    "# imitation_net.summary()\n",
    "\n",
    "# create a connected\n",
    "# model = Concatenate(axis=1)([])\n",
    "\n",
    "# gen_net = Model(inputs=[org_img, mask], outputs=imitation_net)\n",
    "# and define the final output of the generator as the drawn erased area + original non erased area\n",
    "# imitation * mask + org_img * (1 - mask)\n",
    "# just_generated_area will have 1 where mask is, erased_image will have 1 where mask is not\n",
    "# combined is a completed image ready to be passed to discriminator\n",
    "# just_generated_area = Multiply()([imitation, mask])\n",
    "# completed_image = Add()([\n",
    "#     just_generated_area,\n",
    "#     erased_image\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# now lets create a planned out network\n",
    "generator_container = Model(inputs=[org_img, mask], outputs=[completed_image])\n",
    "generator_container\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
