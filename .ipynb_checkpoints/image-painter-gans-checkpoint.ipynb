{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Reshape, Lambda, Flatten, Activation, Conv2D, Conv2DTranspose, Dense, Input, Subtract, Add, Multiply\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Sequential, Model\n",
    "from keras.engine.network import Network\n",
    "from keras.optimizers import Adadelta\n",
    "import keras.backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_shape = (256,256,3)\n",
    "local_shape = (128,128,3)\n",
    "optimizer = Adadelta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_generator(input_shape=(256, 256, 3)):\n",
    "    in_layer = Input(shape=input_shape)\n",
    "\n",
    "    model = Conv2D(64, kernel_size=5, strides=1, padding='same',\n",
    "                     dilation_rate=(1, 1))(in_layer)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2D(128, kernel_size=3, strides=2,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(128, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2D(256, kernel_size=3, strides=2,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(2, 2))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(4, 4))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(8, 8))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(16, 16))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2DTranspose(128, kernel_size=4, strides=2,\n",
    "                              padding='same')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(128, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2DTranspose(64, kernel_size=4, strides=2,\n",
    "                              padding='same')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(32, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2D(3, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('sigmoid')(model)\n",
    "    model_gen = Model(inputs=in_layer, outputs=model)\n",
    "    model_gen.name = 'Gener8tor'\n",
    "    return model_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_discriminator(global_shape=(256, 256, 3), local_shape=(128, 128, 3)):\n",
    "    def crop_image(img, crop):\n",
    "        return tf.image.crop_to_bounding_box(img,\n",
    "                                             crop[1],\n",
    "                                             crop[0],\n",
    "                                             crop[3] - crop[1],\n",
    "                                             crop[2] - crop[0])\n",
    "\n",
    "    in_pts = Input(shape=(4,), dtype='int32')\n",
    "    cropping = Lambda(lambda x: K.map_fn(lambda y: crop_image(y[0], y[1]), elems=x, dtype=tf.float32),\n",
    "                      output_shape=local_shape)\n",
    "    g_img = Input(shape=global_shape)\n",
    "    l_img = cropping([g_img, in_pts])\n",
    "\n",
    "    # Local Discriminator\n",
    "    x_l = Conv2D(64, kernel_size=5, strides=2, padding='same')(l_img)\n",
    "    x_l = BatchNormalization()(x_l)\n",
    "    x_l = Activation('relu')(x_l)\n",
    "    x_l = Conv2D(128, kernel_size=5, strides=2, padding='same')(x_l)\n",
    "    x_l = BatchNormalization()(x_l)\n",
    "    x_l = Activation('relu')(x_l)\n",
    "    x_l = Conv2D(256, kernel_size=5, strides=2, padding='same')(x_l)\n",
    "    x_l = BatchNormalization()(x_l)\n",
    "    x_l = Activation('relu')(x_l)\n",
    "    x_l = Conv2D(512, kernel_size=5, strides=2, padding='same')(x_l)\n",
    "    x_l = BatchNormalization()(x_l)\n",
    "    x_l = Activation('relu')(x_l)\n",
    "    x_l = Conv2D(512, kernel_size=5, strides=2, padding='same')(x_l)\n",
    "    x_l = BatchNormalization()(x_l)\n",
    "    x_l = Activation('relu')(x_l)\n",
    "    x_l = Flatten()(x_l)\n",
    "    x_l = Dense(1024, activation='relu')(x_l)\n",
    "\n",
    "    # Global Discriminator\n",
    "    x_g = Conv2D(64, kernel_size=5, strides=2, padding='same')(g_img)\n",
    "    x_g = BatchNormalization()(x_g)\n",
    "    x_g = Activation('relu')(x_g)\n",
    "    x_g = Conv2D(128, kernel_size=5, strides=2, padding='same')(x_g)\n",
    "    x_g = BatchNormalization()(x_g)\n",
    "    x_g = Activation('relu')(x_g)\n",
    "    x_g = Conv2D(256, kernel_size=5, strides=2, padding='same')(x_g)\n",
    "    x_g = BatchNormalization()(x_g)\n",
    "    x_g = Activation('relu')(x_g)\n",
    "    x_g = Conv2D(512, kernel_size=5, strides=2, padding='same')(x_g)\n",
    "    x_g = BatchNormalization()(x_g)\n",
    "    x_g = Activation('relu')(x_g)\n",
    "    x_g = Conv2D(512, kernel_size=5, strides=2, padding='same')(x_g)\n",
    "    x_g = BatchNormalization()(x_g)\n",
    "    x_g = Activation('relu')(x_g)\n",
    "    x_g = Conv2D(512, kernel_size=5, strides=2, padding='same')(x_g)\n",
    "    x_g = BatchNormalization()(x_g)\n",
    "    x_g = Activation('relu')(x_g)\n",
    "    x_g = Flatten()(x_g)\n",
    "    x_g = Dense(1024, activation='relu')(x_g)\n",
    "\n",
    "    x = Concatenate(axis=1)([x_l, x_g])\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model_disc = Model(inputs=[g_img, in_pts], outputs=x)\n",
    "    model_disc.name = 'Discimi-hater'\n",
    "    return model_disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def view_models(model, filename):\n",
    "    from keras.utils import plot_model\n",
    "    plot_model(model, to_file=filename, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def full_gen_layer(full_img, mask, ones):\n",
    "    from keras.layers import Concatenate\n",
    "\n",
    "    # grab the inverse mask, that only shows the masked areas\n",
    "    # 1 - mask\n",
    "    inverse_mask = Subtract()([ones, mask])\n",
    "\n",
    "    # which outputs the erased_image as input\n",
    "    # full_img * (1 - mask)\n",
    "    erased_image = Multiply()([full_img, inverse_mask])\n",
    "\n",
    "    # view our net\n",
    "    gen_model = model_generator(global_shape)\n",
    "    # print(gen_model)\n",
    "\n",
    "    # pass in the erased_image as input\n",
    "    gen_model = gen_model(erased_image)\n",
    "    # print(gen_model)\n",
    "\n",
    "    gen_brain = Model(inputs=[full_img, mask, ones], outputs=gen_model)\n",
    "    # print(gen_brain)\n",
    "    view_models(gen_brain, 'summaries/gen_brain.png')\n",
    "\n",
    "    gen_brain.compile(\n",
    "        loss='mse',\n",
    "        optimizer=optimizer\n",
    "    )\n",
    "    # gen_brain.summary()\n",
    "    return gen_brain, gen_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def full_disc_layer(global_shape, local_shape, full_img, clip_coords):\n",
    "    # the discriminator side\n",
    "    disc_model = model_discriminator(global_shape, local_shape)\n",
    "\n",
    "    disc_model = disc_model([full_img, clip_coords])\n",
    "    disc_model\n",
    "    # print(disc_model)\n",
    "\n",
    "    disc_brain = Model(inputs=[full_img, clip_coords], outputs=disc_model)\n",
    "    disc_brain.compile(loss='binary_crossentropy',\n",
    "                        optimizer=optimizer)\n",
    "    # disc_brain.summary()\n",
    "    view_models(disc_brain, 'summaries/disc_brain.png')\n",
    "    return disc_brain, disc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-65867558da68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mgen_brain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_gen_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdisc_brain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_disc_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_coords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_brain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-8577cf3062ad>\u001b[0m in \u001b[0;36mfull_disc_layer\u001b[0;34m(global_shape, local_shape, full_img, clip_coords)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdisc_brain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfull_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_coords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisc_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     disc_brain.compile(loss='binary_crossentropy',\n\u001b[0;32m---> 11\u001b[0;31m                         optimizer=optimizer)\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;31m# disc_brain.summary()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mview_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_brain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'summaries/disc_brain.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optimizer' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "full_img = Input(shape=global_shape)\n",
    "clip_img = Input(shape=local_shape)\n",
    "mask = Input(shape=(global_shape[0], global_shape[1], 1))\n",
    "ones = Input(shape=(global_shape[0], global_shape[1], 1))\n",
    "clip_coords = Input(shape=(4,), dtype='int32')\n",
    "\n",
    "gen_brain, gen_model = full_gen_layer(full_img, mask, ones)\n",
    "disc_brain, disc_model = full_disc_layer(global_shape, local_shape, full_img, clip_coords)\n",
    "\n",
    "print(gen_brain)\n",
    "print(disc_brain)\n",
    "\n",
    "print(gen_model)\n",
    "print(disc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 0.0004\n",
    "\n",
    "# the final brain\n",
    "disc_model.trainable = False\n",
    "connected_disc = Model(inputs=[full_img, clip_coords], outputs=disc_model)\n",
    "connected_disc.name = 'Connected-Discrimi-Hater'\n",
    "print(connected_disc)\n",
    "\n",
    "brain = Model(inputs=[full_img, mask, ones, clip_coords], outputs=[gen_model, connected_disc([gen_model, clip_coords])])\n",
    "brain.compile(loss=['mse', 'binary_crossentropy'],\n",
    "                      loss_weights=[1.0, alpha], optimizer=optimizer)\n",
    "brain.summary()\n",
    "view_models(brain, 'summaries/brain.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class DataGenerator(object):\n",
    "    # time for data generator stuff...\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
