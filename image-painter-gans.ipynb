{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Reshape, Lambda, Flatten, Activation, Conv2D, Conv2DTranspose, Dense, Input, Subtract, Add, Multiply\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Sequential, Model\n",
    "from keras.engine.network import Network\n",
    "from keras.optimizers import Adadelta\n",
    "import keras.backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_shape = (256,256,3)\n",
    "local_shape = (128,128,3)\n",
    "optimizer = Adadelta()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the GANs\n",
    "From scratch, and combining each neural net together, until we create a master brain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primative Generator Net\n",
    "This does not include the masks, we only define the images being inputted. We will add the masks later (turning into an augmented net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_generator(input_shape=(256, 256, 3)):\n",
    "    in_layer = Input(shape=input_shape)\n",
    "\n",
    "    model = Conv2D(64, kernel_size=5, strides=1, padding='same',\n",
    "                     dilation_rate=(1, 1))(in_layer)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2D(128, kernel_size=3, strides=2,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(128, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2D(256, kernel_size=3, strides=2,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(2, 2))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(4, 4))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(8, 8))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(16, 16))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2DTranspose(128, kernel_size=4, strides=2,\n",
    "                              padding='same')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(128, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2DTranspose(64, kernel_size=4, strides=2,\n",
    "                              padding='same')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(32, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2D(3, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('sigmoid')(model)\n",
    "    model_gen = Model(inputs=in_layer, outputs=model)\n",
    "    model_gen.name = 'Gener8tor'\n",
    "    return model_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primative Discriminator Net\n",
    "This accounts for the masks and input images, but is not connected to anything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_discriminator(global_shape=(256, 256, 3), local_shape=(128, 128, 3)):\n",
    "    def crop_image(img, crop):\n",
    "        return tf.image.crop_to_bounding_box(img,\n",
    "                                             crop[1],\n",
    "                                             crop[0],\n",
    "                                             crop[3] - crop[1],\n",
    "                                             crop[2] - crop[0])\n",
    "\n",
    "    in_pts = Input(shape=(4,), dtype='int32')\n",
    "    cropping = Lambda(lambda x: K.map_fn(lambda y: crop_image(y[0], y[1]), elems=x, dtype=tf.float32),\n",
    "                      output_shape=local_shape)\n",
    "    g_img = Input(shape=global_shape)\n",
    "    l_img = cropping([g_img, in_pts])\n",
    "\n",
    "    # Local Discriminator\n",
    "    x_l = Conv2D(64, kernel_size=5, strides=2, padding='same')(l_img)\n",
    "    x_l = BatchNormalization()(x_l)\n",
    "    x_l = Activation('relu')(x_l)\n",
    "    x_l = Conv2D(128, kernel_size=5, strides=2, padding='same')(x_l)\n",
    "    x_l = BatchNormalization()(x_l)\n",
    "    x_l = Activation('relu')(x_l)\n",
    "    x_l = Conv2D(256, kernel_size=5, strides=2, padding='same')(x_l)\n",
    "    x_l = BatchNormalization()(x_l)\n",
    "    x_l = Activation('relu')(x_l)\n",
    "    x_l = Conv2D(512, kernel_size=5, strides=2, padding='same')(x_l)\n",
    "    x_l = BatchNormalization()(x_l)\n",
    "    x_l = Activation('relu')(x_l)\n",
    "    x_l = Conv2D(512, kernel_size=5, strides=2, padding='same')(x_l)\n",
    "    x_l = BatchNormalization()(x_l)\n",
    "    x_l = Activation('relu')(x_l)\n",
    "    x_l = Flatten()(x_l)\n",
    "    x_l = Dense(1024, activation='relu')(x_l)\n",
    "\n",
    "    # Global Discriminator\n",
    "    x_g = Conv2D(64, kernel_size=5, strides=2, padding='same')(g_img)\n",
    "    x_g = BatchNormalization()(x_g)\n",
    "    x_g = Activation('relu')(x_g)\n",
    "    x_g = Conv2D(128, kernel_size=5, strides=2, padding='same')(x_g)\n",
    "    x_g = BatchNormalization()(x_g)\n",
    "    x_g = Activation('relu')(x_g)\n",
    "    x_g = Conv2D(256, kernel_size=5, strides=2, padding='same')(x_g)\n",
    "    x_g = BatchNormalization()(x_g)\n",
    "    x_g = Activation('relu')(x_g)\n",
    "    x_g = Conv2D(512, kernel_size=5, strides=2, padding='same')(x_g)\n",
    "    x_g = BatchNormalization()(x_g)\n",
    "    x_g = Activation('relu')(x_g)\n",
    "    x_g = Conv2D(512, kernel_size=5, strides=2, padding='same')(x_g)\n",
    "    x_g = BatchNormalization()(x_g)\n",
    "    x_g = Activation('relu')(x_g)\n",
    "    x_g = Conv2D(512, kernel_size=5, strides=2, padding='same')(x_g)\n",
    "    x_g = BatchNormalization()(x_g)\n",
    "    x_g = Activation('relu')(x_g)\n",
    "    x_g = Flatten()(x_g)\n",
    "    x_g = Dense(1024, activation='relu')(x_g)\n",
    "\n",
    "    x = Concatenate(axis=1)([x_l, x_g])\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model_disc = Model(inputs=[g_img, in_pts], outputs=x)\n",
    "    model_disc.name = 'Discimi-hater'\n",
    "    return model_disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def view_models(model, filename):\n",
    "    from keras.utils import plot_model\n",
    "    plot_model(model, to_file=filename, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmented Generator Net\n",
    "We connect the masks now, turning the primitive net more advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def full_gen_layer(full_img, mask, ones):\n",
    "    from keras.layers import Concatenate\n",
    "\n",
    "    # grab the inverse mask, that only shows the masked areas\n",
    "    # 1 - mask\n",
    "    inverse_mask = Subtract()([ones, mask])\n",
    "\n",
    "    # which outputs the erased_image as input\n",
    "    # full_img * (1 - mask)\n",
    "    erased_image = Multiply()([full_img, inverse_mask])\n",
    "\n",
    "    # view our net\n",
    "    gen_model = model_generator(global_shape)\n",
    "    # print(gen_model)\n",
    "\n",
    "    # pass in the erased_image as input\n",
    "    gen_model = gen_model(erased_image)\n",
    "    # print(gen_model)\n",
    "\n",
    "    gen_brain = Model(inputs=[full_img, mask, ones], outputs=gen_model)\n",
    "    # print(gen_brain)\n",
    "    view_models(gen_brain, 'summaries/gen_brain.png')\n",
    "\n",
    "    gen_brain.compile(\n",
    "        loss='mse',\n",
    "        optimizer=optimizer\n",
    "    )\n",
    "    # gen_brain.summary()\n",
    "    return gen_brain, gen_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connected Discriminator Net\n",
    "We connect the primitive discriminator net to the output of the augmented generator net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def full_disc_layer(global_shape, local_shape, full_img, clip_coords):\n",
    "    # the discriminator side\n",
    "    disc_model = model_discriminator(global_shape, local_shape)\n",
    "\n",
    "    disc_model = disc_model([full_img, clip_coords])\n",
    "    disc_model\n",
    "    # print(disc_model)\n",
    "\n",
    "    disc_brain = Model(inputs=[full_img, clip_coords], outputs=disc_model)\n",
    "    disc_brain.compile(loss='binary_crossentropy',\n",
    "                        optimizer=optimizer)\n",
    "    # disc_brain.summary()\n",
    "    view_models(disc_brain, 'summaries/disc_brain.png')\n",
    "    return disc_brain, disc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.training.Model object at 0x126aae278>\n",
      "<keras.engine.training.Model object at 0x1282f2b38>\n",
      "Tensor(\"Gener8tor/activation_17/Sigmoid:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "Tensor(\"Discimi-hater/dense_3/Sigmoid:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "full_img = Input(shape=global_shape)\n",
    "clip_img = Input(shape=local_shape)\n",
    "mask = Input(shape=(global_shape[0], global_shape[1], 1))\n",
    "ones = Input(shape=(global_shape[0], global_shape[1], 1))\n",
    "clip_coords = Input(shape=(4,), dtype='int32')\n",
    "\n",
    "gen_brain, gen_model = full_gen_layer(full_img, mask, ones)\n",
    "disc_brain, disc_model = full_disc_layer(global_shape, local_shape, full_img, clip_coords)\n",
    "\n",
    "print(gen_brain)\n",
    "print(disc_brain)\n",
    "\n",
    "print(gen_model)\n",
    "print(disc_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect the Neural Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.training.Model object at 0x125c0e8d0>\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "subtract_1 (Subtract)           (None, 256, 256, 1)  0           input_4[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 256, 256, 3)  0           input_1[0][0]                    \n",
      "                                                                 subtract_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Gener8tor (Model)               (None, 256, 256, 3)  6076495     multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Connected-Discrimi-Hater (Model (None, 1)            45070593    Gener8tor[1][0]                  \n",
      "                                                                 input_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 51,147,088\n",
      "Trainable params: 51,134,218\n",
      "Non-trainable params: 12,870\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.0004\n",
    "\n",
    "# the final brain\n",
    "disc_model.trainable = False\n",
    "connected_disc = Model(inputs=[full_img, clip_coords], outputs=disc_model)\n",
    "connected_disc.name = 'Connected-Discrimi-Hater'\n",
    "print(connected_disc)\n",
    "\n",
    "brain = Model(inputs=[full_img, mask, ones, clip_coords], outputs=[gen_model, connected_disc([gen_model, clip_coords])])\n",
    "brain.compile(loss=['mse', 'binary_crossentropy'],\n",
    "                      loss_weights=[1.0, alpha], optimizer=optimizer)\n",
    "brain.summary()\n",
    "view_models(brain, 'summaries/brain.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup the Image Preprocessor\n",
    "Using a memory-efficient Python generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kangzehuang/anaconda3/envs/ComputerVision/lib/python3.6/site-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/Users/kangzehuang/anaconda3/envs/ComputerVision/lib/python3.6/site-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.lib.io import file_io\n",
    "from google.cloud import storage\n",
    "import google\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# creds, _ = google.auth.default()\n",
    "client = storage.Client()\n",
    "bucket = client.bucket('lsun-roomsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/bedroom_val/0/0/0/0/0/0/00000089629ce3ba87bae003073896ba01988dee.webp\n",
      "images/bedroom_val/0/0/0/0/0/1/000001ec5684cb40f432f996f8a38e5d076114d8.webp\n",
      "images/bedroom_val/0/0/0/0/0/3/0000036b25b1ae054cdf2e3ee954fe2d21db6ae0.webp\n",
      "images/bedroom_val/0/0/0/0/0/b/00000b94a63ae2e1c08b4e7452d088156a9a8273.webp\n",
      "images/bedroom_val/0/0/0/0/1/2/0000128037967f0d4b7ba748a80d5b248d1203f8.webp\n",
      "images/bedroom_val/0/0/0/0/1/5/000015122516efa29c25870b6b60fafe2fae1513.webp\n",
      "images/bedroom_val/0/0/0/0/1/c/00001c1755ac170e5382876232aec651f6bda841.webp\n",
      "images/bedroom_val/0/0/0/0/2/3/000023924aa8e512db983cba65e30cc106123ce3.webp\n",
      "images/bedroom_val/0/0/0/0/3/5/0000356acb787613fc8d8715cc6c182c05173535.webp\n",
      "images/bedroom_val/0/0/0/0/3/f/00003f8ec7ff5d59865ab2b6fb58bc663ace3b23.webp\n",
      "0. Processing images/bedroom_val/0/0/0/0/0/0/00000089629ce3ba87bae003073896ba01988dee.webp\n",
      "1. Processing images/bedroom_val/0/0/0/0/0/1/000001ec5684cb40f432f996f8a38e5d076114d8.webp\n",
      "2. Processing images/bedroom_val/0/0/0/0/0/3/0000036b25b1ae054cdf2e3ee954fe2d21db6ae0.webp\n",
      "3. Processing images/bedroom_val/0/0/0/0/0/b/00000b94a63ae2e1c08b4e7452d088156a9a8273.webp\n",
      "4. Processing images/bedroom_val/0/0/0/0/1/2/0000128037967f0d4b7ba748a80d5b248d1203f8.webp\n",
      "(5, 256, 256, 3)\n",
      "(5, 4)\n",
      "(5, 256, 256, 1)\n",
      "5. Processing images/bedroom_val/0/0/0/0/1/5/000015122516efa29c25870b6b60fafe2fae1513.webp\n",
      "6. Processing images/bedroom_val/0/0/0/0/1/c/00001c1755ac170e5382876232aec651f6bda841.webp\n",
      "7. Processing images/bedroom_val/0/0/0/0/2/3/000023924aa8e512db983cba65e30cc106123ce3.webp\n",
      "8. Processing images/bedroom_val/0/0/0/0/3/5/0000356acb787613fc8d8715cc6c182c05173535.webp\n",
      "9. Processing images/bedroom_val/0/0/0/0/3/f/00003f8ec7ff5d59865ab2b6fb58bc663ace3b23.webp\n",
      "(5, 256, 256, 3)\n",
      "(5, 4)\n",
      "(5, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "# playable version of DataGenerator()\n",
    "class FuckAround():\n",
    "    # list the bucket and directory within\n",
    "    bucketname = 'gs://lsun-roomsets'\n",
    "    directory = 'images/bedroom_val/'\n",
    "    \n",
    "    # loop through all the files and view first X images (count)\n",
    "    count = 0\n",
    "    max_count = 10\n",
    "    # store the raw img urls here\n",
    "    img_urls = []\n",
    "    for blob in bucket.list_blobs(prefix=directory):\n",
    "        if count >= max_count:\n",
    "            break\n",
    "        print(blob.name)\n",
    "        count += 1\n",
    "        img_urls.append(blob.name)\n",
    "        \n",
    "    # store the resized images here\n",
    "    images = []\n",
    "    points = []\n",
    "    masks = []\n",
    "    \n",
    "    # CONSTANTS\n",
    "    # mask size limits\n",
    "    hole_min = 64\n",
    "    hole_max = 128\n",
    "    # batch limits\n",
    "    batch_size = 5\n",
    "    max_batches = 3\n",
    "    batch_count = 0\n",
    "    # image sizes\n",
    "    image_size = (256,256)\n",
    "    local_size = (128,128)\n",
    "    \n",
    "    for idx, img_url in enumerate(img_urls):\n",
    "        # we use tf...file_io.FileIO to grab the file\n",
    "        with file_io.FileIO(f'{bucketname}/{img_url}', 'rb') as f:\n",
    "            # and use PIL to convert into an RGB image\n",
    "            img = Image.open(f).convert('RGB')\n",
    "            # then convert the RGB image to an array so that cv2 can read it\n",
    "            img = np.asarray(img, dtype=\"uint8\")\n",
    "            # resize images\n",
    "            img_resized = cv2.resize(img, image_size)[:,:,::-1]\n",
    "            # take a look at the images\n",
    "            # cv2.imshow(f'image_{idx}_resized', img_resized)\n",
    "            # cv2.waitKey(0)\n",
    "            # cv2.destroyWindow(f'image_{idx}_resized')\n",
    "            # add the resized photo to self.images\n",
    "            images.append(img_resized)\n",
    "            print(f'{idx}. Processing {img_url}')\n",
    "            \n",
    "            # now lets create the random points where we will apply a mask (erase parts of image)\n",
    "            # recall that image_size=(256,256) and local_size=(128,128)\n",
    "            x1 = np.random.randint(0, image_size[0] - local_size[0] + 1)\n",
    "            y1 = np.random.randint(0, image_size[1] - local_size[1] + 1)\n",
    "            x2, y2 = np.array([x1, y1]) + np.array(local_size)\n",
    "            points.append([x1,y1,x2,y2])\n",
    "            \n",
    "            # and we also randomly generate width and height of those masks\n",
    "            w, h = np.random.randint(hole_min, hole_max, 2)\n",
    "            p1 = x1 + np.random.randint(0, local_size[0] - w)\n",
    "            q1 = y1 + np.random.randint(0, local_size[1] - h)\n",
    "            p2 = p1 + w\n",
    "            q2 = q1 + h\n",
    "            # now create the array of zeros\n",
    "            m = np.zeros((image_size[0], image_size[1], 1), dtype=np.uint8)\n",
    "            # everywhere there should be the mask, make the value one (everywhere else is zero)\n",
    "            m[q1:q2 + 1, p1:p2 + 1] = 1\n",
    "            # finally append it to the self.masks\n",
    "            masks.append(m)\n",
    "            \n",
    "            # print the batch of data when batch size reached\n",
    "            if len(images) == batch_size:\n",
    "                print(np.array(images).shape)\n",
    "                print(np.array(points).shape)\n",
    "                print(np.array(masks).shape)\n",
    "                inputs = np.asarray(images, dtype=np.float32) / 255\n",
    "                points = np.asarray(points, dtype=np.int32)\n",
    "                masks = np.asarray(masks, dtype=np.float32)\n",
    "                \n",
    "                # reset\n",
    "                images = []\n",
    "                points = []\n",
    "                masks = []\n",
    "                batch_count += 1\n",
    "                \n",
    "            if batch_count > max_batches:\n",
    "                break\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataGenerator\n",
    "Using a memory-efficient Python generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataGenerator(object):\n",
    "    # initialize by retreiving the photos\n",
    "    def __init__(self, bucketname, input_dir, image_size, local_size):\n",
    "        # bucketname = 'gs://lsun-roomsets'\n",
    "        # input_dir = 'images/bedroom_train/'\n",
    "        # image_size = (256,256)\n",
    "        # local_size = (128,128)\n",
    "        self.image_size = image_size\n",
    "        self.local_size = local_size\n",
    "        self.reset()\n",
    "        self.img_file_list = []\n",
    "        # for now we get max self.count photos and add them to self.img_file_list\n",
    "        for blob in bucket.list_blobs(prefix=input_dir):\n",
    "            self.img_file_list.append(blob.name)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.img_file_list)\n",
    "    \n",
    "    # we also track the preprocessed images, points, and masks\n",
    "    def reset(self):\n",
    "        self.images = []\n",
    "        self.points = []\n",
    "        self.masks = []\n",
    "    \n",
    "    # iterates over self.img_file_list and does preprocessing\n",
    "    def flow(self, batch_size, hole_min=64, hole_max=128):\n",
    "        np.random.shuffle(self.img_file_list)\n",
    "        for idx, img_url in enumerate(self.img_file_list):\n",
    "            # we use tf...file_io.FileIO to grab the file\n",
    "            with file_io.FileIO(f'{bucketname}/{img_url}', 'rb') as f:\n",
    "                # and use PIL to convert into an RGB image\n",
    "                img = Image.open(f).convert('RGB')\n",
    "                # then convert the RGB image to an array so that cv2 can read it\n",
    "                img = np.asarray(img, dtype=\"uint8\")\n",
    "                # resize images\n",
    "                img_resized = cv2.resize(img, self.image_size)[:,:,::-1]\n",
    "                # take a look at the images\n",
    "                # cv2.imshow(f'image_{idx}_resized', img_resized)\n",
    "                # cv2.waitKey(0)\n",
    "                # cv2.destroyWindow(f'image_{idx}_resized')\n",
    "                # add the resized photo to self.images\n",
    "                self.images.append(img_resized)\n",
    "\n",
    "                # now lets create the random location (aka. X,Y points) where we will apply a mask (aka. erase parts of image)\n",
    "                # recall that image_size=(256,256) and local_size=(128,128)\n",
    "                x1 = np.random.randint(0, self.image_size[0] - self.local_size[0] + 1)\n",
    "                y1 = np.random.randint(0, self.image_size[1] - self.local_size[1] + 1)\n",
    "                x2, y2 = np.array([x1, y1]) + np.array(self.local_size)\n",
    "                self.points.append([x1,y1,x2,y2])\n",
    "                # and we also randomly generate width and height of those masks\n",
    "                w, h = np.random.randint(hole_min, hole_max, 2)\n",
    "                p1 = x1 + np.random.randint(0, self.local_size[0] - w)\n",
    "                q1 = y1 + np.random.randint(0, self.local_size[1] - h)\n",
    "                p2 = p1 + w\n",
    "                q2 = q1 + h\n",
    "                # now create the array of zeros\n",
    "                m = np.zeros((self.image_size[0], self.image_size[1], 1), dtype=np.uint8)\n",
    "                # everywhere there should be the mask, make the value one (everywhere else is zero)\n",
    "                m[q1:q2 + 1, p1:p2 + 1] = 1\n",
    "                # finally append it to the self.masks\n",
    "                self.masks.append(m)\n",
    "\n",
    "                # yeild the batch of data when batch size reached\n",
    "                if len(self.images) == batch_size:\n",
    "                    images = np.asarray(self.images, dtype=np.float32) / 255\n",
    "                    points = np.asarray(self.points, dtype=np.int32)\n",
    "                    masks = np.asarray(self.masks, dtype=np.float32)\n",
    "                    self.reset()\n",
    "                    yield images, points, masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Start the Training\n",
    "With hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import generic_utils\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "input_shape = (256, 256, 3)\n",
    "local_shape = (128, 128, 3)\n",
    "batch_size = 4\n",
    "n_epochs = 2\n",
    "tc = int(n_epochs * 0.18)\n",
    "td = int(n_epochs * 0.02)\n",
    "alpha = 0.0004\n",
    "gen_img_count = 0\n",
    "\n",
    "# input/output directories\n",
    "bucketname = \"gs://lsun-roomsets\"\n",
    "result_dir = \"outputs/\"\n",
    "input_dir = \"images/bedroom_val/\"\n",
    "\n",
    "# data generator\n",
    "train_datagen = DataGenerator(bucketname, input_dir, input_shape[:2], local_shape[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4/300 [..............................] - ETA: 45:03 - Disc Loss: : 7.9712 - Gen mse: : 0.0318------\n",
      "[[[[0.36589742 0.4796006  0.44764042]\n",
      "   [0.36185306 0.41578954 0.3460058 ]\n",
      "   [0.37443367 0.42118323 0.3720826 ]\n",
      "   ...\n",
      "   [0.36393288 0.4677691  0.37229434]\n",
      "   [0.3426466  0.4257327  0.29105556]\n",
      "   [0.44055435 0.43270466 0.46049324]]\n",
      "\n",
      "  [[0.34002724 0.40354356 0.38993517]\n",
      "   [0.3091823  0.30161405 0.2817053 ]\n",
      "   [0.3567484  0.27552795 0.3383008 ]\n",
      "   ...\n",
      "   [0.35678348 0.32234716 0.32693538]\n",
      "   [0.2518351  0.28943342 0.26035097]\n",
      "   [0.4094386  0.39001936 0.45509684]]\n",
      "\n",
      "  [[0.34217232 0.46607283 0.3471618 ]\n",
      "   [0.31349322 0.32837093 0.27957046]\n",
      "   [0.33640525 0.32222697 0.32603547]\n",
      "   ...\n",
      "   [0.29314953 0.37072426 0.35085097]\n",
      "   [0.33512673 0.35648164 0.31695822]\n",
      "   [0.41808552 0.39816713 0.44146225]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.36135992 0.40068713 0.3354983 ]\n",
      "   [0.25738204 0.25466618 0.30283841]\n",
      "   [0.3530785  0.29712328 0.3140073 ]\n",
      "   ...\n",
      "   [0.29844412 0.27467063 0.25029653]\n",
      "   [0.2867688  0.25674936 0.2298857 ]\n",
      "   [0.34938726 0.34767112 0.4201331 ]]\n",
      "\n",
      "  [[0.32515895 0.42772135 0.33375347]\n",
      "   [0.2745894  0.26736495 0.2752264 ]\n",
      "   [0.27903068 0.29806504 0.2680425 ]\n",
      "   ...\n",
      "   [0.25906482 0.25068066 0.24499463]\n",
      "   [0.25562087 0.24097629 0.26406005]\n",
      "   [0.3770653  0.34016624 0.4064135 ]]\n",
      "\n",
      "  [[0.447993   0.42093825 0.4734669 ]\n",
      "   [0.37054798 0.3247511  0.39447844]\n",
      "   [0.43294218 0.28481728 0.3700007 ]\n",
      "   ...\n",
      "   [0.36270475 0.32177502 0.39216572]\n",
      "   [0.41228506 0.29803735 0.35924876]\n",
      "   [0.443027   0.36272097 0.5198582 ]]]\n",
      "\n",
      "\n",
      " [[[0.6446117  0.47934142 0.55830795]\n",
      "   [0.59969395 0.59359825 0.6473616 ]\n",
      "   [0.76772255 0.73105055 0.5142813 ]\n",
      "   ...\n",
      "   [0.90657073 0.9168553  0.79797983]\n",
      "   [0.8964403  0.7710159  0.8450489 ]\n",
      "   [0.72520554 0.5588342  0.69946283]]\n",
      "\n",
      "  [[0.652507   0.6844379  0.5879316 ]\n",
      "   [0.7086631  0.5722886  0.5681487 ]\n",
      "   [0.7879791  0.764661   0.7093461 ]\n",
      "   ...\n",
      "   [0.9412227  0.89995843 0.83565795]\n",
      "   [0.89548135 0.9262284  0.77421594]\n",
      "   [0.8038564  0.8814136  0.74677235]]\n",
      "\n",
      "  [[0.6986735  0.70482343 0.67371446]\n",
      "   [0.6810029  0.86018133 0.77586997]\n",
      "   [0.84507394 0.8618385  0.6344314 ]\n",
      "   ...\n",
      "   [0.9527582  0.9807026  0.88898724]\n",
      "   [0.78333455 0.90643007 0.9764129 ]\n",
      "   [0.80671877 0.928352   0.48296624]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.36508006 0.39801878 0.3364604 ]\n",
      "   [0.2571013  0.24633145 0.30866927]\n",
      "   [0.29457143 0.2920967  0.34314394]\n",
      "   ...\n",
      "   [0.31328872 0.27182686 0.27728948]\n",
      "   [0.29326862 0.2767908  0.26508465]\n",
      "   [0.34109125 0.37112236 0.41115496]]\n",
      "\n",
      "  [[0.3190198  0.4246147  0.32033914]\n",
      "   [0.26120633 0.2665292  0.24616252]\n",
      "   [0.28449753 0.27612907 0.26298735]\n",
      "   ...\n",
      "   [0.26074302 0.28029984 0.29200327]\n",
      "   [0.24949756 0.2542701  0.2644706 ]\n",
      "   [0.3939461  0.3779991  0.4202253 ]]\n",
      "\n",
      "  [[0.44538796 0.41889095 0.46427038]\n",
      "   [0.37719202 0.31401852 0.3823157 ]\n",
      "   [0.41888714 0.28619024 0.38491046]\n",
      "   ...\n",
      "   [0.36235926 0.30948052 0.3897509 ]\n",
      "   [0.4177472  0.32172227 0.37429565]\n",
      "   [0.43983606 0.37022132 0.5066212 ]]]\n",
      "\n",
      "\n",
      " [[[0.40920007 0.47674745 0.48255008]\n",
      "   [0.42694792 0.4759629  0.46311522]\n",
      "   [0.51442677 0.47714305 0.45561013]\n",
      "   ...\n",
      "   [0.42068422 0.5670382  0.37617812]\n",
      "   [0.3912529  0.5055688  0.38940683]\n",
      "   [0.47541586 0.51238453 0.46139959]]\n",
      "\n",
      "  [[0.39170462 0.4814224  0.5017399 ]\n",
      "   [0.6080429  0.3728833  0.36904737]\n",
      "   [0.49855548 0.6083715  0.6058022 ]\n",
      "   ...\n",
      "   [0.5347303  0.4672884  0.4064074 ]\n",
      "   [0.41823933 0.39046526 0.4721094 ]\n",
      "   [0.48061875 0.49117738 0.5154217 ]]\n",
      "\n",
      "  [[0.5365771  0.5190366  0.41752926]\n",
      "   [0.50298476 0.6372236  0.62655145]\n",
      "   [0.58734053 0.5977395  0.5900527 ]\n",
      "   ...\n",
      "   [0.45064127 0.5575093  0.5248269 ]\n",
      "   [0.41113546 0.5185068  0.41633475]\n",
      "   [0.4721159  0.4754596  0.45151612]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.37875718 0.36927444 0.33521438]\n",
      "   [0.24159037 0.26892623 0.29132864]\n",
      "   [0.32061288 0.3041281  0.34039858]\n",
      "   ...\n",
      "   [0.6164901  0.70079666 0.59665513]\n",
      "   [0.57004625 0.5506309  0.5011419 ]\n",
      "   [0.5362033  0.5600403  0.6111908 ]]\n",
      "\n",
      "  [[0.31101814 0.42641717 0.30886704]\n",
      "   [0.24684812 0.2454618  0.27517134]\n",
      "   [0.29466456 0.2780437  0.29790634]\n",
      "   ...\n",
      "   [0.5377838  0.5642578  0.61391157]\n",
      "   [0.34698346 0.35229787 0.53571004]\n",
      "   [0.46394837 0.50223005 0.52102536]]\n",
      "\n",
      "  [[0.4590949  0.4193623  0.46476343]\n",
      "   [0.3823326  0.31298116 0.40174028]\n",
      "   [0.40382627 0.2959462  0.36832067]\n",
      "   ...\n",
      "   [0.5053827  0.54912865 0.49610272]\n",
      "   [0.48889282 0.49945736 0.41127303]\n",
      "   [0.474456   0.44546506 0.49521515]]]\n",
      "\n",
      "\n",
      " [[[0.36265457 0.4677376  0.42963374]\n",
      "   [0.35861012 0.38645455 0.34187025]\n",
      "   [0.34422448 0.3824887  0.37239972]\n",
      "   ...\n",
      "   [0.3318132  0.40249392 0.33278936]\n",
      "   [0.3258677  0.3894776  0.29790854]\n",
      "   [0.45542005 0.41269985 0.44231117]]\n",
      "\n",
      "  [[0.32036346 0.3761786  0.37345508]\n",
      "   [0.30892754 0.25963718 0.28774583]\n",
      "   [0.30162507 0.30077487 0.33159396]\n",
      "   ...\n",
      "   [0.32606688 0.26106483 0.30289295]\n",
      "   [0.2860258  0.2564485  0.25829023]\n",
      "   [0.39513472 0.36805874 0.42418793]]\n",
      "\n",
      "  [[0.33150372 0.4650855  0.3429905 ]\n",
      "   [0.28363478 0.3184291  0.3296477 ]\n",
      "   [0.32914084 0.27033427 0.28482798]\n",
      "   ...\n",
      "   [0.29959974 0.29560238 0.2526734 ]\n",
      "   [0.26223376 0.2634525  0.2535847 ]\n",
      "   [0.3954631  0.37078917 0.40394655]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.43353477 0.41575134 0.39582738]\n",
      "   [0.3004785  0.32879433 0.31862745]\n",
      "   [0.37440267 0.3487706  0.44300574]\n",
      "   ...\n",
      "   [0.31617934 0.39188385 0.2936928 ]\n",
      "   [0.36632925 0.3307914  0.2722048 ]\n",
      "   [0.4038033  0.39862376 0.42122272]]\n",
      "\n",
      "  [[0.352539   0.44119528 0.3562191 ]\n",
      "   [0.2828396  0.28538692 0.32399362]\n",
      "   [0.35661325 0.3520399  0.3071392 ]\n",
      "   ...\n",
      "   [0.29986757 0.30103683 0.32122222]\n",
      "   [0.24518658 0.32055223 0.2731284 ]\n",
      "   [0.4125786  0.41512293 0.39753658]]\n",
      "\n",
      "  [[0.45198518 0.40988725 0.49389797]\n",
      "   [0.37156463 0.34698996 0.45010787]\n",
      "   [0.47373518 0.33580154 0.4598716 ]\n",
      "   ...\n",
      "   [0.38978186 0.34782863 0.4262951 ]\n",
      "   [0.4380628  0.36099094 0.40523237]\n",
      "   [0.44614142 0.39010552 0.5259218 ]]]]\n",
      "<class 'numpy.ndarray'>\n",
      "(4, 256, 256, 3)\n",
      "------\n",
      "[[[0.36589742 0.4796006  0.44764042]\n",
      "  [0.36185306 0.41578954 0.3460058 ]\n",
      "  [0.37443367 0.42118323 0.3720826 ]\n",
      "  ...\n",
      "  [0.36393288 0.4677691  0.37229434]\n",
      "  [0.3426466  0.4257327  0.29105556]\n",
      "  [0.44055435 0.43270466 0.46049324]]\n",
      "\n",
      " [[0.34002724 0.40354356 0.38993517]\n",
      "  [0.3091823  0.30161405 0.2817053 ]\n",
      "  [0.3567484  0.27552795 0.3383008 ]\n",
      "  ...\n",
      "  [0.35678348 0.32234716 0.32693538]\n",
      "  [0.2518351  0.28943342 0.26035097]\n",
      "  [0.4094386  0.39001936 0.45509684]]\n",
      "\n",
      " [[0.34217232 0.46607283 0.3471618 ]\n",
      "  [0.31349322 0.32837093 0.27957046]\n",
      "  [0.33640525 0.32222697 0.32603547]\n",
      "  ...\n",
      "  [0.29314953 0.37072426 0.35085097]\n",
      "  [0.33512673 0.35648164 0.31695822]\n",
      "  [0.41808552 0.39816713 0.44146225]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.36135992 0.40068713 0.3354983 ]\n",
      "  [0.25738204 0.25466618 0.30283841]\n",
      "  [0.3530785  0.29712328 0.3140073 ]\n",
      "  ...\n",
      "  [0.29844412 0.27467063 0.25029653]\n",
      "  [0.2867688  0.25674936 0.2298857 ]\n",
      "  [0.34938726 0.34767112 0.4201331 ]]\n",
      "\n",
      " [[0.32515895 0.42772135 0.33375347]\n",
      "  [0.2745894  0.26736495 0.2752264 ]\n",
      "  [0.27903068 0.29806504 0.2680425 ]\n",
      "  ...\n",
      "  [0.25906482 0.25068066 0.24499463]\n",
      "  [0.25562087 0.24097629 0.26406005]\n",
      "  [0.3770653  0.34016624 0.4064135 ]]\n",
      "\n",
      " [[0.447993   0.42093825 0.4734669 ]\n",
      "  [0.37054798 0.3247511  0.39447844]\n",
      "  [0.43294218 0.28481728 0.3700007 ]\n",
      "  ...\n",
      "  [0.36270475 0.32177502 0.39216572]\n",
      "  [0.41228506 0.29803735 0.35924876]\n",
      "  [0.443027   0.36272097 0.5198582 ]]]\n",
      "<class 'numpy.ndarray'>\n",
      "(256, 256, 3)\n",
      "  8/300 [..............................] - ETA: 44:29 - Disc Loss: : 7.9712 - Gen mse: : 0.0348------\n",
      "[[[[0.42269614 0.4702223  0.4232633 ]\n",
      "   [0.49398482 0.4487674  0.46578085]\n",
      "   [0.53966635 0.535562   0.50288117]\n",
      "   ...\n",
      "   [0.47305715 0.5669047  0.4432729 ]\n",
      "   [0.3834469  0.4989246  0.4153746 ]\n",
      "   [0.48384196 0.4794947  0.4308526 ]]\n",
      "\n",
      "  [[0.41867113 0.45517454 0.42381433]\n",
      "   [0.5626746  0.3788834  0.38696375]\n",
      "   [0.50024784 0.4394347  0.70195776]\n",
      "   ...\n",
      "   [0.49858052 0.39828822 0.382391  ]\n",
      "   [0.32928383 0.40472138 0.4236811 ]\n",
      "   [0.50851184 0.46011177 0.50146824]]\n",
      "\n",
      "  [[0.5573812  0.5062877  0.5570447 ]\n",
      "   [0.5705279  0.6408108  0.66757715]\n",
      "   [0.58374846 0.58601844 0.60400975]\n",
      "   ...\n",
      "   [0.4967378  0.5254645  0.52132237]\n",
      "   [0.39307475 0.4520693  0.4307561 ]\n",
      "   [0.40830538 0.47013718 0.5127485 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5508358  0.52005607 0.5087248 ]\n",
      "   [0.4010969  0.50170237 0.57660985]\n",
      "   [0.68182063 0.59138507 0.57545465]\n",
      "   ...\n",
      "   [0.5195558  0.63020116 0.47323152]\n",
      "   [0.40163046 0.44251242 0.4005716 ]\n",
      "   [0.4401597  0.48332757 0.5582757 ]]\n",
      "\n",
      "  [[0.42111778 0.5369668  0.39336094]\n",
      "   [0.40833563 0.46639585 0.40927878]\n",
      "   [0.4916167  0.48530245 0.4697031 ]\n",
      "   ...\n",
      "   [0.42895728 0.5545811  0.42317432]\n",
      "   [0.33522484 0.44499198 0.34829083]\n",
      "   [0.40482974 0.4635588  0.4818074 ]]\n",
      "\n",
      "  [[0.4740324  0.42266023 0.50743437]\n",
      "   [0.35818526 0.44303954 0.50924355]\n",
      "   [0.5192543  0.44812807 0.54696816]\n",
      "   ...\n",
      "   [0.4246686  0.4376716  0.4729405 ]\n",
      "   [0.45420122 0.41613346 0.37221065]\n",
      "   [0.45945475 0.4232571  0.5008728 ]]]\n",
      "\n",
      "\n",
      " [[[0.42812225 0.4920448  0.48704687]\n",
      "   [0.5395068  0.5466312  0.4959946 ]\n",
      "   [0.63131154 0.53304666 0.5335898 ]\n",
      "   ...\n",
      "   [0.46775538 0.5572452  0.44281307]\n",
      "   [0.39190143 0.4848422  0.35033286]\n",
      "   [0.5119346  0.47219884 0.48426875]]\n",
      "\n",
      "  [[0.42791152 0.5333596  0.5104554 ]\n",
      "   [0.57345974 0.44117883 0.33911923]\n",
      "   [0.5945619  0.5858167  0.6657664 ]\n",
      "   ...\n",
      "   [0.4934639  0.46216628 0.39189163]\n",
      "   [0.37402898 0.4326646  0.41588444]\n",
      "   [0.4398665  0.49254888 0.43843016]]\n",
      "\n",
      "  [[0.51790506 0.585859   0.5271145 ]\n",
      "   [0.58112067 0.725936   0.66231805]\n",
      "   [0.77832174 0.5990603  0.66562665]\n",
      "   ...\n",
      "   [0.44430658 0.4468962  0.4991103 ]\n",
      "   [0.34530324 0.45764244 0.38138855]\n",
      "   [0.48378113 0.50557107 0.42894128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.378313   0.38971505 0.44092107]\n",
      "   [0.2774968  0.33013538 0.31991443]\n",
      "   [0.3660538  0.3710076  0.41750163]\n",
      "   ...\n",
      "   [0.274931   0.2921792  0.26815912]\n",
      "   [0.29260996 0.27659428 0.2560272 ]\n",
      "   [0.35769343 0.35058093 0.40261605]]\n",
      "\n",
      "  [[0.31242102 0.44169864 0.30758274]\n",
      "   [0.27984107 0.29560283 0.34545922]\n",
      "   [0.3254544  0.3306607  0.3534505 ]\n",
      "   ...\n",
      "   [0.27523205 0.27635548 0.2619046 ]\n",
      "   [0.26133156 0.25767383 0.27730602]\n",
      "   [0.38952664 0.3542136  0.40548784]]\n",
      "\n",
      "  [[0.441317   0.42392477 0.48193812]\n",
      "   [0.36906824 0.36484042 0.43544865]\n",
      "   [0.4647039  0.32776046 0.42439842]\n",
      "   ...\n",
      "   [0.36012304 0.31314722 0.39392138]\n",
      "   [0.43049043 0.31637254 0.35494477]\n",
      "   [0.4137497  0.35939264 0.52210945]]]\n",
      "\n",
      "\n",
      " [[[0.38434866 0.45141047 0.4421902 ]\n",
      "   [0.4040799  0.40298212 0.45098618]\n",
      "   [0.45256454 0.49301517 0.4560177 ]\n",
      "   ...\n",
      "   [0.40563595 0.46713918 0.34616622]\n",
      "   [0.33399314 0.39877018 0.3473477 ]\n",
      "   [0.48287606 0.4182151  0.44065443]]\n",
      "\n",
      "  [[0.35648605 0.4555405  0.48463303]\n",
      "   [0.43067437 0.358077   0.2931742 ]\n",
      "   [0.45179024 0.3533086  0.5248207 ]\n",
      "   ...\n",
      "   [0.41789013 0.3678497  0.31287995]\n",
      "   [0.28629902 0.31511667 0.3309492 ]\n",
      "   [0.40728983 0.39615253 0.4285238 ]]\n",
      "\n",
      "  [[0.45187458 0.550398   0.43717325]\n",
      "   [0.45369068 0.4922171  0.43719384]\n",
      "   [0.53661436 0.51319915 0.5013686 ]\n",
      "   ...\n",
      "   [0.3914332  0.42198694 0.39779618]\n",
      "   [0.32018816 0.3878646  0.31802422]\n",
      "   [0.40800717 0.41803887 0.42074794]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.38768685 0.39012447 0.37069806]\n",
      "   [0.2740131  0.28694046 0.30678406]\n",
      "   [0.33284843 0.32606122 0.33856225]\n",
      "   ...\n",
      "   [0.30776006 0.3034764  0.28070885]\n",
      "   [0.28688946 0.26451114 0.24100539]\n",
      "   [0.34203577 0.36008996 0.4117027 ]]\n",
      "\n",
      "  [[0.31786656 0.42032164 0.34163538]\n",
      "   [0.2512921  0.26870495 0.27859727]\n",
      "   [0.29863575 0.3141969  0.27517992]\n",
      "   ...\n",
      "   [0.2744676  0.28251356 0.24447933]\n",
      "   [0.24876039 0.2593303  0.27979395]\n",
      "   [0.371166   0.35921812 0.38415527]]\n",
      "\n",
      "  [[0.4409607  0.4236028  0.47511178]\n",
      "   [0.36739156 0.32910934 0.39259872]\n",
      "   [0.45952305 0.27722222 0.3809517 ]\n",
      "   ...\n",
      "   [0.36649075 0.30565616 0.36807874]\n",
      "   [0.40736586 0.33660945 0.37756073]\n",
      "   [0.4422563  0.37184215 0.518152  ]]]\n",
      "\n",
      "\n",
      " [[[0.35573804 0.46124843 0.3948148 ]\n",
      "   [0.3532736  0.40828845 0.3384033 ]\n",
      "   [0.36299628 0.37984094 0.38191018]\n",
      "   ...\n",
      "   [0.38564575 0.42971054 0.36693418]\n",
      "   [0.33579648 0.3997908  0.31315082]\n",
      "   [0.4541021  0.4421592  0.46298033]]\n",
      "\n",
      "  [[0.32851636 0.37840822 0.38066113]\n",
      "   [0.2677435  0.29375452 0.2801948 ]\n",
      "   [0.29295433 0.26313627 0.3426884 ]\n",
      "   ...\n",
      "   [0.38546374 0.31429672 0.30001453]\n",
      "   [0.30053028 0.2812749  0.32004154]\n",
      "   [0.41835907 0.38993132 0.42886114]]\n",
      "\n",
      "  [[0.34159386 0.44986337 0.32708064]\n",
      "   [0.29865345 0.30560058 0.32076934]\n",
      "   [0.3267381  0.31759983 0.31446648]\n",
      "   ...\n",
      "   [0.3531867  0.40876704 0.38161746]\n",
      "   [0.31149134 0.36861002 0.30279496]\n",
      "   [0.4321101  0.4319322  0.44594505]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.39328247 0.3850747  0.40067905]\n",
      "   [0.30375564 0.32834542 0.33201623]\n",
      "   [0.352796   0.2877739  0.4508262 ]\n",
      "   ...\n",
      "   [0.30346054 0.36247525 0.2787254 ]\n",
      "   [0.32525596 0.31728303 0.27862647]\n",
      "   [0.37085372 0.42570698 0.4401684 ]]\n",
      "\n",
      "  [[0.35189137 0.41399485 0.30637604]\n",
      "   [0.2739829  0.2821006  0.26555553]\n",
      "   [0.34863478 0.30991626 0.3599946 ]\n",
      "   ...\n",
      "   [0.31410494 0.36278883 0.3033399 ]\n",
      "   [0.26094878 0.26600608 0.28813365]\n",
      "   [0.4053482  0.37985557 0.396849  ]]\n",
      "\n",
      "  [[0.44715175 0.40100712 0.48035932]\n",
      "   [0.3473178  0.3380064  0.41979486]\n",
      "   [0.4676177  0.31412312 0.4017083 ]\n",
      "   ...\n",
      "   [0.3771744  0.3378781  0.40091878]\n",
      "   [0.4289599  0.36557475 0.36156547]\n",
      "   [0.43610018 0.37870458 0.50471187]]]]\n",
      "<class 'numpy.ndarray'>\n",
      "(4, 256, 256, 3)\n",
      "------\n",
      "[[[0.42269614 0.4702223  0.4232633 ]\n",
      "  [0.49398482 0.4487674  0.46578085]\n",
      "  [0.53966635 0.535562   0.50288117]\n",
      "  ...\n",
      "  [0.47305715 0.5669047  0.4432729 ]\n",
      "  [0.3834469  0.4989246  0.4153746 ]\n",
      "  [0.48384196 0.4794947  0.4308526 ]]\n",
      "\n",
      " [[0.41867113 0.45517454 0.42381433]\n",
      "  [0.5626746  0.3788834  0.38696375]\n",
      "  [0.50024784 0.4394347  0.70195776]\n",
      "  ...\n",
      "  [0.49858052 0.39828822 0.382391  ]\n",
      "  [0.32928383 0.40472138 0.4236811 ]\n",
      "  [0.50851184 0.46011177 0.50146824]]\n",
      "\n",
      " [[0.5573812  0.5062877  0.5570447 ]\n",
      "  [0.5705279  0.6408108  0.66757715]\n",
      "  [0.58374846 0.58601844 0.60400975]\n",
      "  ...\n",
      "  [0.4967378  0.5254645  0.52132237]\n",
      "  [0.39307475 0.4520693  0.4307561 ]\n",
      "  [0.40830538 0.47013718 0.5127485 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.5508358  0.52005607 0.5087248 ]\n",
      "  [0.4010969  0.50170237 0.57660985]\n",
      "  [0.68182063 0.59138507 0.57545465]\n",
      "  ...\n",
      "  [0.5195558  0.63020116 0.47323152]\n",
      "  [0.40163046 0.44251242 0.4005716 ]\n",
      "  [0.4401597  0.48332757 0.5582757 ]]\n",
      "\n",
      " [[0.42111778 0.5369668  0.39336094]\n",
      "  [0.40833563 0.46639585 0.40927878]\n",
      "  [0.4916167  0.48530245 0.4697031 ]\n",
      "  ...\n",
      "  [0.42895728 0.5545811  0.42317432]\n",
      "  [0.33522484 0.44499198 0.34829083]\n",
      "  [0.40482974 0.4635588  0.4818074 ]]\n",
      "\n",
      " [[0.4740324  0.42266023 0.50743437]\n",
      "  [0.35818526 0.44303954 0.50924355]\n",
      "  [0.5192543  0.44812807 0.54696816]\n",
      "  ...\n",
      "  [0.4246686  0.4376716  0.4729405 ]\n",
      "  [0.45420122 0.41613346 0.37221065]\n",
      "  [0.45945475 0.4232571  0.5008728 ]]]\n",
      "<class 'numpy.ndarray'>\n",
      "(256, 256, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12/300 [>.............................] - ETA: 44:18 - Disc Loss: : 7.9712 - Gen mse: : 0.0376------\n",
      "[[[[0.3503689  0.47131974 0.41943514]\n",
      "   [0.343667   0.4061773  0.33580345]\n",
      "   [0.33751556 0.38179937 0.3625638 ]\n",
      "   ...\n",
      "   [0.68485    0.6898206  0.5824831 ]\n",
      "   [0.6107756  0.6116496  0.69307494]\n",
      "   [0.6210017  0.5651629  0.5256727 ]]\n",
      "\n",
      "  [[0.326141   0.38949484 0.36696884]\n",
      "   [0.2751603  0.27070194 0.26896358]\n",
      "   [0.30033877 0.25649887 0.31987974]\n",
      "   ...\n",
      "   [0.72365814 0.6607537  0.60292834]\n",
      "   [0.5144404  0.7649419  0.565985  ]\n",
      "   [0.58395463 0.53872764 0.5372266 ]]\n",
      "\n",
      "  [[0.33208907 0.446341   0.3055503 ]\n",
      "   [0.27823603 0.29609746 0.28720716]\n",
      "   [0.3123147  0.31246525 0.288781  ]\n",
      "   ...\n",
      "   [0.7669569  0.85223776 0.69396263]\n",
      "   [0.49137893 0.6304601  0.7637132 ]\n",
      "   [0.5840204  0.6673381  0.4715996 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.3746186  0.3840214  0.3396663 ]\n",
      "   [0.24607956 0.2623305  0.25759062]\n",
      "   [0.3166487  0.27878836 0.32891813]\n",
      "   ...\n",
      "   [0.30991638 0.3014236  0.2479616 ]\n",
      "   [0.2746045  0.2377121  0.2404559 ]\n",
      "   [0.3463941  0.34884173 0.41304567]]\n",
      "\n",
      "  [[0.3034621  0.41563243 0.31950036]\n",
      "   [0.26798218 0.25197497 0.24904652]\n",
      "   [0.26983243 0.28159446 0.2742979 ]\n",
      "   ...\n",
      "   [0.27354416 0.24814488 0.23983365]\n",
      "   [0.25352827 0.23307614 0.23509884]\n",
      "   [0.364191   0.37400886 0.40250653]]\n",
      "\n",
      "  [[0.44061416 0.40956643 0.45579728]\n",
      "   [0.37598005 0.31647867 0.39147994]\n",
      "   [0.4299142  0.29313365 0.3661963 ]\n",
      "   ...\n",
      "   [0.36390772 0.28918055 0.3544879 ]\n",
      "   [0.42132917 0.30734214 0.36849892]\n",
      "   [0.42595375 0.36170974 0.5183065 ]]]\n",
      "\n",
      "\n",
      " [[[0.3852118  0.4564697  0.45398808]\n",
      "   [0.36429626 0.41084987 0.33995998]\n",
      "   [0.37880322 0.41813853 0.44653794]\n",
      "   ...\n",
      "   [0.39804843 0.4449223  0.33446196]\n",
      "   [0.3414271  0.39049283 0.36503303]\n",
      "   [0.4668465  0.4518731  0.4522467 ]]\n",
      "\n",
      "  [[0.34343073 0.39241704 0.3847498 ]\n",
      "   [0.34502003 0.34771448 0.28676298]\n",
      "   [0.31991646 0.31104293 0.39025944]\n",
      "   ...\n",
      "   [0.4038403  0.3333305  0.34191996]\n",
      "   [0.31828052 0.33262387 0.32155788]\n",
      "   [0.4222082  0.40096164 0.4262802 ]]\n",
      "\n",
      "  [[0.3801352  0.43393365 0.3591967 ]\n",
      "   [0.32920638 0.3452421  0.36899117]\n",
      "   [0.36708397 0.3298859  0.3428158 ]\n",
      "   ...\n",
      "   [0.40372735 0.39727554 0.31634116]\n",
      "   [0.31777772 0.29685646 0.27880487]\n",
      "   [0.42420414 0.3881164  0.40344688]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.36755332 0.39098537 0.3463559 ]\n",
      "   [0.25721413 0.26245946 0.2694055 ]\n",
      "   [0.28929892 0.272032   0.308853  ]\n",
      "   ...\n",
      "   [0.28321207 0.31497622 0.25056866]\n",
      "   [0.3118301  0.26938507 0.2294645 ]\n",
      "   [0.34826607 0.36675984 0.441798  ]]\n",
      "\n",
      "  [[0.3124626  0.40996248 0.32357675]\n",
      "   [0.25801805 0.2589663  0.25835538]\n",
      "   [0.2801024  0.2889052  0.2476985 ]\n",
      "   ...\n",
      "   [0.27948704 0.2778919  0.29603875]\n",
      "   [0.23745218 0.26585335 0.26748365]\n",
      "   [0.38420567 0.35567495 0.37243772]]\n",
      "\n",
      "  [[0.43151653 0.4087553  0.467481  ]\n",
      "   [0.3634431  0.32190764 0.3941973 ]\n",
      "   [0.45445463 0.273426   0.36996812]\n",
      "   ...\n",
      "   [0.36658332 0.3098466  0.3690669 ]\n",
      "   [0.43446955 0.31932262 0.3781276 ]\n",
      "   [0.43241847 0.37026888 0.5222616 ]]]\n",
      "\n",
      "\n",
      " [[[0.3927673  0.4419085  0.4515942 ]\n",
      "   [0.43166125 0.456088   0.46585572]\n",
      "   [0.51763207 0.49390855 0.4698597 ]\n",
      "   ...\n",
      "   [0.38726753 0.51654613 0.41567674]\n",
      "   [0.35312447 0.44440442 0.37930274]\n",
      "   [0.46301144 0.4528284  0.48077708]]\n",
      "\n",
      "  [[0.36441833 0.46404633 0.48039314]\n",
      "   [0.46016043 0.3651036  0.34634274]\n",
      "   [0.49084052 0.51506335 0.5917336 ]\n",
      "   ...\n",
      "   [0.43828082 0.3645733  0.33898816]\n",
      "   [0.2949766  0.37001255 0.34115842]\n",
      "   [0.4172194  0.40784642 0.45121402]]\n",
      "\n",
      "  [[0.48029226 0.46585447 0.4489629 ]\n",
      "   [0.44944978 0.6244408  0.47652453]\n",
      "   [0.5772516  0.56276065 0.578291  ]\n",
      "   ...\n",
      "   [0.41468728 0.43644413 0.49608707]\n",
      "   [0.37008277 0.3765788  0.35955426]\n",
      "   [0.4498558  0.42320442 0.47065145]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.37570617 0.39423826 0.35448015]\n",
      "   [0.24932314 0.26955032 0.2746433 ]\n",
      "   [0.3067646  0.32349315 0.30078653]\n",
      "   ...\n",
      "   [0.5371106  0.7390496  0.5886552 ]\n",
      "   [0.4266766  0.49387297 0.482319  ]\n",
      "   [0.4749604  0.51927996 0.5159403 ]]\n",
      "\n",
      "  [[0.3286996  0.4153057  0.32278764]\n",
      "   [0.2741859  0.266093   0.2747567 ]\n",
      "   [0.29841137 0.30492583 0.2713818 ]\n",
      "   ...\n",
      "   [0.55713606 0.5794621  0.4696073 ]\n",
      "   [0.428244   0.4151722  0.58456326]\n",
      "   [0.43793097 0.5268433  0.5381254 ]]\n",
      "\n",
      "  [[0.44464535 0.41220912 0.47702703]\n",
      "   [0.37009916 0.3191748  0.4190906 ]\n",
      "   [0.4325697  0.2818998  0.38128036]\n",
      "   ...\n",
      "   [0.49867186 0.5296667  0.46935755]\n",
      "   [0.50362533 0.47044256 0.46744546]\n",
      "   [0.45443553 0.44470707 0.5174424 ]]]\n",
      "\n",
      "\n",
      " [[[0.3698684  0.45921364 0.41441387]\n",
      "   [0.3523474  0.4108289  0.35145018]\n",
      "   [0.38615382 0.39787066 0.3820624 ]\n",
      "   ...\n",
      "   [0.393856   0.476913   0.38018036]\n",
      "   [0.3419544  0.40447658 0.33922437]\n",
      "   [0.47250122 0.44622895 0.4670449 ]]\n",
      "\n",
      "  [[0.33108765 0.40428883 0.39438587]\n",
      "   [0.30988318 0.27551532 0.298198  ]\n",
      "   [0.31046024 0.2836771  0.32998922]\n",
      "   ...\n",
      "   [0.37349302 0.36574045 0.360299  ]\n",
      "   [0.28190687 0.30262464 0.2937796 ]\n",
      "   [0.3789106  0.4001373  0.4357273 ]]\n",
      "\n",
      "  [[0.35348597 0.48416018 0.3553075 ]\n",
      "   [0.3082545  0.38156447 0.32168224]\n",
      "   [0.38482672 0.3397861  0.347351  ]\n",
      "   ...\n",
      "   [0.3815442  0.3791494  0.29206395]\n",
      "   [0.3418415  0.3759642  0.3011294 ]\n",
      "   [0.4174312  0.38836986 0.45350677]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.4304618  0.40020365 0.38644698]\n",
      "   [0.2874979  0.3069872  0.3916346 ]\n",
      "   [0.40326768 0.39561164 0.39001426]\n",
      "   ...\n",
      "   [0.3010806  0.34122586 0.25786158]\n",
      "   [0.36023763 0.27630997 0.2718341 ]\n",
      "   [0.35988146 0.40709367 0.417093  ]]\n",
      "\n",
      "  [[0.33005074 0.45721146 0.343548  ]\n",
      "   [0.31748557 0.30191332 0.3112643 ]\n",
      "   [0.33499467 0.3094921  0.32300445]\n",
      "   ...\n",
      "   [0.3125645  0.3211163  0.30135685]\n",
      "   [0.24085085 0.25824744 0.2754891 ]\n",
      "   [0.40305182 0.3998098  0.38445336]]\n",
      "\n",
      "  [[0.44252992 0.44015324 0.4572883 ]\n",
      "   [0.387187   0.3512556  0.4430817 ]\n",
      "   [0.45010936 0.35530335 0.39821652]\n",
      "   ...\n",
      "   [0.36706015 0.32089615 0.4153486 ]\n",
      "   [0.43043834 0.36062652 0.36565804]\n",
      "   [0.4263763  0.3730512  0.49930242]]]]\n",
      "<class 'numpy.ndarray'>\n",
      "(4, 256, 256, 3)\n",
      "------\n",
      "[[[0.3503689  0.47131974 0.41943514]\n",
      "  [0.343667   0.4061773  0.33580345]\n",
      "  [0.33751556 0.38179937 0.3625638 ]\n",
      "  ...\n",
      "  [0.68485    0.6898206  0.5824831 ]\n",
      "  [0.6107756  0.6116496  0.69307494]\n",
      "  [0.6210017  0.5651629  0.5256727 ]]\n",
      "\n",
      " [[0.326141   0.38949484 0.36696884]\n",
      "  [0.2751603  0.27070194 0.26896358]\n",
      "  [0.30033877 0.25649887 0.31987974]\n",
      "  ...\n",
      "  [0.72365814 0.6607537  0.60292834]\n",
      "  [0.5144404  0.7649419  0.565985  ]\n",
      "  [0.58395463 0.53872764 0.5372266 ]]\n",
      "\n",
      " [[0.33208907 0.446341   0.3055503 ]\n",
      "  [0.27823603 0.29609746 0.28720716]\n",
      "  [0.3123147  0.31246525 0.288781  ]\n",
      "  ...\n",
      "  [0.7669569  0.85223776 0.69396263]\n",
      "  [0.49137893 0.6304601  0.7637132 ]\n",
      "  [0.5840204  0.6673381  0.4715996 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.3746186  0.3840214  0.3396663 ]\n",
      "  [0.24607956 0.2623305  0.25759062]\n",
      "  [0.3166487  0.27878836 0.32891813]\n",
      "  ...\n",
      "  [0.30991638 0.3014236  0.2479616 ]\n",
      "  [0.2746045  0.2377121  0.2404559 ]\n",
      "  [0.3463941  0.34884173 0.41304567]]\n",
      "\n",
      " [[0.3034621  0.41563243 0.31950036]\n",
      "  [0.26798218 0.25197497 0.24904652]\n",
      "  [0.26983243 0.28159446 0.2742979 ]\n",
      "  ...\n",
      "  [0.27354416 0.24814488 0.23983365]\n",
      "  [0.25352827 0.23307614 0.23509884]\n",
      "  [0.364191   0.37400886 0.40250653]]\n",
      "\n",
      " [[0.44061416 0.40956643 0.45579728]\n",
      "  [0.37598005 0.31647867 0.39147994]\n",
      "  [0.4299142  0.29313365 0.3661963 ]\n",
      "  ...\n",
      "  [0.36390772 0.28918055 0.3544879 ]\n",
      "  [0.42132917 0.30734214 0.36849892]\n",
      "  [0.42595375 0.36170974 0.5183065 ]]]\n",
      "<class 'numpy.ndarray'>\n",
      "(256, 256, 3)\n",
      " 16/300 [>.............................] - ETA: 43:40 - Disc Loss: : 7.9712 - Gen mse: : 0.0373------\n",
      "[[[[0.3870686  0.4600637  0.46429032]\n",
      "   [0.35784614 0.4091983  0.35854104]\n",
      "   [0.38575745 0.39812142 0.3842119 ]\n",
      "   ...\n",
      "   [0.4157439  0.5061921  0.38560387]\n",
      "   [0.36057684 0.45982632 0.40076783]\n",
      "   [0.47028095 0.47103745 0.44964218]]\n",
      "\n",
      "  [[0.33690634 0.4067803  0.40043786]\n",
      "   [0.29810864 0.2938916  0.29380614]\n",
      "   [0.32396242 0.30310106 0.38840032]\n",
      "   ...\n",
      "   [0.46007922 0.36254072 0.4374428 ]\n",
      "   [0.36652952 0.35975343 0.39123064]\n",
      "   [0.4327502  0.44661364 0.44913545]]\n",
      "\n",
      "  [[0.3574821  0.42744783 0.3678132 ]\n",
      "   [0.31383118 0.3724043  0.31567752]\n",
      "   [0.40973645 0.34150946 0.34869787]\n",
      "   ...\n",
      "   [0.4234221  0.4642831  0.48668423]\n",
      "   [0.39123204 0.3832742  0.4088162 ]\n",
      "   [0.47066492 0.45876637 0.48275948]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.37899414 0.3771568  0.3881963 ]\n",
      "   [0.27618244 0.27078936 0.33324087]\n",
      "   [0.31320247 0.30719477 0.34619242]\n",
      "   ...\n",
      "   [0.51108354 0.6818244  0.5963104 ]\n",
      "   [0.49529597 0.5788127  0.35814926]\n",
      "   [0.49181563 0.49720618 0.5300311 ]]\n",
      "\n",
      "  [[0.33976528 0.44174218 0.28725883]\n",
      "   [0.26556963 0.294236   0.3095676 ]\n",
      "   [0.29827854 0.28752133 0.29534122]\n",
      "   ...\n",
      "   [0.47000268 0.56430334 0.4580335 ]\n",
      "   [0.38604948 0.46996224 0.43083823]\n",
      "   [0.42459175 0.446123   0.43754485]]\n",
      "\n",
      "  [[0.46056685 0.42387596 0.48763344]\n",
      "   [0.37352496 0.31873316 0.4248935 ]\n",
      "   [0.43268833 0.34494218 0.38173062]\n",
      "   ...\n",
      "   [0.4124652  0.40440655 0.5144119 ]\n",
      "   [0.46213865 0.5014874  0.43026778]\n",
      "   [0.47592875 0.43217435 0.5337316 ]]]\n",
      "\n",
      "\n",
      " [[[0.36438677 0.46878266 0.4341494 ]\n",
      "   [0.37133098 0.41642916 0.34151784]\n",
      "   [0.40275884 0.40594396 0.4072566 ]\n",
      "   ...\n",
      "   [0.3818348  0.4575295  0.38395992]\n",
      "   [0.34594846 0.4061404  0.3195536 ]\n",
      "   [0.47140095 0.43882102 0.45326823]]\n",
      "\n",
      "  [[0.34409732 0.4054191  0.39848676]\n",
      "   [0.30176595 0.31697518 0.2779304 ]\n",
      "   [0.33003858 0.30977148 0.4259634 ]\n",
      "   ...\n",
      "   [0.35547364 0.32726178 0.352414  ]\n",
      "   [0.3220184  0.32686928 0.30690384]\n",
      "   [0.39264554 0.37457544 0.43680543]]\n",
      "\n",
      "  [[0.36573243 0.46066985 0.35610393]\n",
      "   [0.33680996 0.33224893 0.33538055]\n",
      "   [0.34233567 0.36269033 0.35126868]\n",
      "   ...\n",
      "   [0.37641242 0.39878795 0.3683064 ]\n",
      "   [0.32073757 0.35905856 0.31564492]\n",
      "   [0.43713343 0.39476418 0.45119873]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.38958102 0.40587538 0.37062508]\n",
      "   [0.24552646 0.2814575  0.3072417 ]\n",
      "   [0.355923   0.3341077  0.33858344]\n",
      "   ...\n",
      "   [0.35215554 0.37942657 0.3564619 ]\n",
      "   [0.34421986 0.35076743 0.36781326]\n",
      "   [0.39310002 0.4058141  0.4083742 ]]\n",
      "\n",
      "  [[0.33045626 0.44858947 0.31183353]\n",
      "   [0.2612258  0.3021878  0.2950933 ]\n",
      "   [0.31048495 0.29598516 0.35939246]\n",
      "   ...\n",
      "   [0.3052934  0.31650782 0.3485426 ]\n",
      "   [0.2734059  0.31210446 0.29301932]\n",
      "   [0.44977906 0.42040637 0.41603574]]\n",
      "\n",
      "  [[0.44941905 0.4070323  0.47987685]\n",
      "   [0.35575935 0.32520074 0.43293887]\n",
      "   [0.43040344 0.3383642  0.43771142]\n",
      "   ...\n",
      "   [0.39227235 0.34657857 0.40196067]\n",
      "   [0.4426061  0.37211883 0.3902232 ]\n",
      "   [0.4361211  0.41071904 0.519778  ]]]\n",
      "\n",
      "\n",
      " [[[0.3687168  0.4436751  0.4290835 ]\n",
      "   [0.3641505  0.41094738 0.34865594]\n",
      "   [0.40773588 0.40086877 0.3957395 ]\n",
      "   ...\n",
      "   [0.37431496 0.42677885 0.35734907]\n",
      "   [0.34643853 0.40656373 0.31595284]\n",
      "   [0.455463   0.41849107 0.44623306]]\n",
      "\n",
      "  [[0.34185237 0.40358338 0.3628452 ]\n",
      "   [0.32698706 0.29382658 0.3156844 ]\n",
      "   [0.35005042 0.34407833 0.40741152]\n",
      "   ...\n",
      "   [0.36513615 0.2874758  0.33009058]\n",
      "   [0.28104317 0.28907627 0.24841039]\n",
      "   [0.38584393 0.3623396  0.40491453]]\n",
      "\n",
      "  [[0.38224375 0.48236498 0.3993877 ]\n",
      "   [0.3028406  0.42877772 0.3357379 ]\n",
      "   [0.39004797 0.33934247 0.37851337]\n",
      "   ...\n",
      "   [0.30340037 0.30791885 0.34380478]\n",
      "   [0.29619902 0.3071033  0.2728746 ]\n",
      "   [0.39998803 0.37890452 0.41646987]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.39061576 0.39956918 0.33671328]\n",
      "   [0.25740257 0.26800656 0.3235466 ]\n",
      "   [0.33978352 0.34278286 0.31525907]\n",
      "   ...\n",
      "   [0.36821914 0.3780886  0.3397763 ]\n",
      "   [0.3132591  0.27338815 0.29682156]\n",
      "   [0.3697057  0.42080867 0.4120214 ]]\n",
      "\n",
      "  [[0.32574078 0.41502368 0.32409912]\n",
      "   [0.2635635  0.25467834 0.27116254]\n",
      "   [0.2873529  0.3006801  0.26420552]\n",
      "   ...\n",
      "   [0.272505   0.35137692 0.34712997]\n",
      "   [0.26619467 0.29282033 0.2926572 ]\n",
      "   [0.39490247 0.39946985 0.44468555]]\n",
      "\n",
      "  [[0.44777185 0.4100287  0.4628612 ]\n",
      "   [0.37550125 0.31575456 0.41890025]\n",
      "   [0.4453162  0.30226412 0.38027316]\n",
      "   ...\n",
      "   [0.40199882 0.3213078  0.42276198]\n",
      "   [0.44078884 0.37568125 0.37967363]\n",
      "   [0.4344548  0.3714497  0.50542206]]]\n",
      "\n",
      "\n",
      " [[[0.42141247 0.4505434  0.4746956 ]\n",
      "   [0.41582873 0.41983807 0.41293797]\n",
      "   [0.48448256 0.45729417 0.4792403 ]\n",
      "   ...\n",
      "   [0.34459028 0.4251232  0.33603084]\n",
      "   [0.33435124 0.39128444 0.29500344]\n",
      "   [0.44526815 0.41593653 0.45381093]]\n",
      "\n",
      "  [[0.37339607 0.44367075 0.43600088]\n",
      "   [0.39872625 0.3842583  0.3468147 ]\n",
      "   [0.4987065  0.44710818 0.6301957 ]\n",
      "   ...\n",
      "   [0.32863936 0.2852313  0.3104634 ]\n",
      "   [0.2640935  0.2849514  0.26503152]\n",
      "   [0.3861704  0.36958006 0.42844737]]\n",
      "\n",
      "  [[0.46045333 0.44818756 0.44273713]\n",
      "   [0.4232563  0.5580568  0.43483612]\n",
      "   [0.5350935  0.48545662 0.52634835]\n",
      "   ...\n",
      "   [0.27848843 0.34030616 0.32646075]\n",
      "   [0.28361163 0.2971807  0.24152318]\n",
      "   [0.4073411  0.37520534 0.41422844]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.37599924 0.42242298 0.35910973]\n",
      "   [0.2565498  0.2977943  0.29131636]\n",
      "   [0.3570337  0.32910925 0.35189864]\n",
      "   ...\n",
      "   [0.31338403 0.3255773  0.25445446]\n",
      "   [0.31258836 0.28077206 0.24547772]\n",
      "   [0.36455002 0.39622277 0.41755605]]\n",
      "\n",
      "  [[0.32673556 0.42245808 0.32872075]\n",
      "   [0.2629652  0.28695172 0.2727173 ]\n",
      "   [0.29698062 0.32938558 0.288121  ]\n",
      "   ...\n",
      "   [0.28975368 0.3022309  0.28151223]\n",
      "   [0.26093155 0.269467   0.27593115]\n",
      "   [0.38943315 0.37976405 0.40121967]]\n",
      "\n",
      "  [[0.45493478 0.41528946 0.4914753 ]\n",
      "   [0.37691975 0.32606694 0.43926212]\n",
      "   [0.427593   0.30846867 0.41650662]\n",
      "   ...\n",
      "   [0.3611427  0.32350525 0.3831406 ]\n",
      "   [0.40141213 0.32932186 0.3656678 ]\n",
      "   [0.44384572 0.36765411 0.5211011 ]]]]\n",
      "<class 'numpy.ndarray'>\n",
      "(4, 256, 256, 3)\n",
      "------\n",
      "[[[0.3870686  0.4600637  0.46429032]\n",
      "  [0.35784614 0.4091983  0.35854104]\n",
      "  [0.38575745 0.39812142 0.3842119 ]\n",
      "  ...\n",
      "  [0.4157439  0.5061921  0.38560387]\n",
      "  [0.36057684 0.45982632 0.40076783]\n",
      "  [0.47028095 0.47103745 0.44964218]]\n",
      "\n",
      " [[0.33690634 0.4067803  0.40043786]\n",
      "  [0.29810864 0.2938916  0.29380614]\n",
      "  [0.32396242 0.30310106 0.38840032]\n",
      "  ...\n",
      "  [0.46007922 0.36254072 0.4374428 ]\n",
      "  [0.36652952 0.35975343 0.39123064]\n",
      "  [0.4327502  0.44661364 0.44913545]]\n",
      "\n",
      " [[0.3574821  0.42744783 0.3678132 ]\n",
      "  [0.31383118 0.3724043  0.31567752]\n",
      "  [0.40973645 0.34150946 0.34869787]\n",
      "  ...\n",
      "  [0.4234221  0.4642831  0.48668423]\n",
      "  [0.39123204 0.3832742  0.4088162 ]\n",
      "  [0.47066492 0.45876637 0.48275948]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.37899414 0.3771568  0.3881963 ]\n",
      "  [0.27618244 0.27078936 0.33324087]\n",
      "  [0.31320247 0.30719477 0.34619242]\n",
      "  ...\n",
      "  [0.51108354 0.6818244  0.5963104 ]\n",
      "  [0.49529597 0.5788127  0.35814926]\n",
      "  [0.49181563 0.49720618 0.5300311 ]]\n",
      "\n",
      " [[0.33976528 0.44174218 0.28725883]\n",
      "  [0.26556963 0.294236   0.3095676 ]\n",
      "  [0.29827854 0.28752133 0.29534122]\n",
      "  ...\n",
      "  [0.47000268 0.56430334 0.4580335 ]\n",
      "  [0.38604948 0.46996224 0.43083823]\n",
      "  [0.42459175 0.446123   0.43754485]]\n",
      "\n",
      " [[0.46056685 0.42387596 0.48763344]\n",
      "  [0.37352496 0.31873316 0.4248935 ]\n",
      "  [0.43268833 0.34494218 0.38173062]\n",
      "  ...\n",
      "  [0.4124652  0.40440655 0.5144119 ]\n",
      "  [0.46213865 0.5014874  0.43026778]\n",
      "  [0.47592875 0.43217435 0.5337316 ]]]\n",
      "<class 'numpy.ndarray'>\n",
      "(256, 256, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20/300 [=>............................] - ETA: 42:34 - Disc Loss: : 7.9712 - Gen mse: : 0.0361------\n",
      "[[[[0.3563316  0.45519364 0.4088742 ]\n",
      "   [0.34963843 0.40177232 0.33683735]\n",
      "   [0.34500223 0.3767555  0.3653191 ]\n",
      "   ...\n",
      "   [0.32795337 0.41059804 0.32107684]\n",
      "   [0.3300417  0.37702805 0.28387484]\n",
      "   [0.43985987 0.39411676 0.43800193]]\n",
      "\n",
      "  [[0.3246005  0.38955003 0.38406205]\n",
      "   [0.2873537  0.28327107 0.2830343 ]\n",
      "   [0.30425683 0.2635256  0.30795786]\n",
      "   ...\n",
      "   [0.32553145 0.25778633 0.29720494]\n",
      "   [0.27167368 0.24783893 0.25150907]\n",
      "   [0.3897106  0.34910053 0.415422  ]]\n",
      "\n",
      "  [[0.3405178  0.43803388 0.31173682]\n",
      "   [0.28677326 0.31971803 0.29878166]\n",
      "   [0.3265509  0.2974176  0.30722687]\n",
      "   ...\n",
      "   [0.26082313 0.29660323 0.29376858]\n",
      "   [0.264296   0.26848808 0.22831477]\n",
      "   [0.39211643 0.3325753  0.41077384]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.36568233 0.37203336 0.32879296]\n",
      "   [0.25039956 0.27398324 0.28343955]\n",
      "   [0.2830021  0.2858105  0.3394029 ]\n",
      "   ...\n",
      "   [0.2943837  0.33171362 0.27733997]\n",
      "   [0.31851262 0.31045905 0.25006077]\n",
      "   [0.35959077 0.36701605 0.40671661]]\n",
      "\n",
      "  [[0.33100018 0.4251989  0.30280828]\n",
      "   [0.2660433  0.26458073 0.2752106 ]\n",
      "   [0.3061156  0.28218958 0.27654913]\n",
      "   ...\n",
      "   [0.28478956 0.26427096 0.27697673]\n",
      "   [0.25307038 0.25294533 0.27500325]\n",
      "   [0.38984194 0.3591069  0.3889791 ]]\n",
      "\n",
      "  [[0.44908625 0.41186926 0.47886032]\n",
      "   [0.36166522 0.33755744 0.40818968]\n",
      "   [0.46902618 0.30716833 0.37300876]\n",
      "   ...\n",
      "   [0.37822518 0.32377505 0.39835617]\n",
      "   [0.41651925 0.33161548 0.37027937]\n",
      "   [0.43837056 0.38042057 0.5079697 ]]]\n",
      "\n",
      "\n",
      " [[[0.40245408 0.46864325 0.43768772]\n",
      "   [0.39388177 0.44594932 0.41394365]\n",
      "   [0.42359087 0.49348325 0.41521057]\n",
      "   ...\n",
      "   [0.56221426 0.65831137 0.4972854 ]\n",
      "   [0.54398376 0.533187   0.38321435]\n",
      "   [0.5605822  0.4308203  0.57866055]]\n",
      "\n",
      "  [[0.3760523  0.46104792 0.43342122]\n",
      "   [0.4029954  0.32910323 0.26341864]\n",
      "   [0.37449986 0.39603966 0.48104152]\n",
      "   ...\n",
      "   [0.6376311  0.56665754 0.5416936 ]\n",
      "   [0.4916833  0.57827073 0.4373956 ]\n",
      "   [0.54918975 0.590217   0.5130231 ]]\n",
      "\n",
      "  [[0.44563726 0.4995531  0.421618  ]\n",
      "   [0.42739207 0.429112   0.38457942]\n",
      "   [0.43046418 0.49372384 0.4860547 ]\n",
      "   ...\n",
      "   [0.6457103  0.7552657  0.5848272 ]\n",
      "   [0.4762569  0.58746064 0.6235405 ]\n",
      "   [0.52798533 0.67747295 0.5650179 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.37527066 0.3884037  0.37443775]\n",
      "   [0.24230689 0.2656545  0.30116826]\n",
      "   [0.32747054 0.32311273 0.31285933]\n",
      "   ...\n",
      "   [0.43644845 0.5117541  0.40421027]\n",
      "   [0.35069835 0.3498257  0.4025088 ]\n",
      "   [0.42583033 0.45154598 0.46967244]]\n",
      "\n",
      "  [[0.30842024 0.4245001  0.30987185]\n",
      "   [0.24793814 0.28172478 0.2791132 ]\n",
      "   [0.30290654 0.31732386 0.2834957 ]\n",
      "   ...\n",
      "   [0.4137089  0.38222152 0.39606324]\n",
      "   [0.28049457 0.31256756 0.35564768]\n",
      "   [0.4256964  0.41740093 0.46018893]]\n",
      "\n",
      "  [[0.44026363 0.41396755 0.48074567]\n",
      "   [0.38683018 0.31973043 0.41866428]\n",
      "   [0.44375232 0.33119327 0.41256452]\n",
      "   ...\n",
      "   [0.4469764  0.4094165  0.40878436]\n",
      "   [0.47337836 0.4061954  0.3876814 ]\n",
      "   [0.43498638 0.40079665 0.5200219 ]]]\n",
      "\n",
      "\n",
      " [[[0.35968837 0.47940317 0.4270773 ]\n",
      "   [0.36658216 0.40557182 0.34509012]\n",
      "   [0.3675275  0.40760937 0.4034631 ]\n",
      "   ...\n",
      "   [0.39947018 0.43935755 0.39074197]\n",
      "   [0.348806   0.45859575 0.3498177 ]\n",
      "   [0.46191642 0.44208896 0.44461673]]\n",
      "\n",
      "  [[0.3351831  0.3859172  0.3831459 ]\n",
      "   [0.31719214 0.27880555 0.28831285]\n",
      "   [0.36004296 0.3116824  0.35750115]\n",
      "   ...\n",
      "   [0.40501136 0.32601076 0.38945976]\n",
      "   [0.31450105 0.31331006 0.30768588]\n",
      "   [0.41114363 0.41198945 0.44630283]]\n",
      "\n",
      "  [[0.34040725 0.45805228 0.32657757]\n",
      "   [0.3206624  0.3226029  0.3421115 ]\n",
      "   [0.33181536 0.3478895  0.32533172]\n",
      "   ...\n",
      "   [0.38461637 0.38727897 0.3472209 ]\n",
      "   [0.32694665 0.36710215 0.31782183]\n",
      "   [0.43627098 0.4090515  0.44355294]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.37879565 0.4018848  0.35348246]\n",
      "   [0.25466892 0.2815745  0.28977722]\n",
      "   [0.2789731  0.30612177 0.3193231 ]\n",
      "   ...\n",
      "   [0.45935878 0.5926132  0.42158055]\n",
      "   [0.43748605 0.43346602 0.32954574]\n",
      "   [0.45789936 0.45021755 0.50869787]]\n",
      "\n",
      "  [[0.311621   0.4314002  0.35823956]\n",
      "   [0.2873997  0.26329738 0.26731735]\n",
      "   [0.30976248 0.28099447 0.27961946]\n",
      "   ...\n",
      "   [0.39525935 0.39242455 0.3675515 ]\n",
      "   [0.2693423  0.3488124  0.3473921 ]\n",
      "   [0.3833707  0.4347144  0.45002827]]\n",
      "\n",
      "  [[0.4511647  0.42505464 0.47985026]\n",
      "   [0.37017754 0.32908294 0.41985768]\n",
      "   [0.43313006 0.29987    0.361853  ]\n",
      "   ...\n",
      "   [0.39044908 0.3913201  0.51073915]\n",
      "   [0.435304   0.40202665 0.44470966]\n",
      "   [0.45918044 0.41469705 0.51082623]]]\n",
      "\n",
      "\n",
      " [[[0.35145676 0.46709216 0.42130756]\n",
      "   [0.33820945 0.39794657 0.3407569 ]\n",
      "   [0.35040286 0.38280022 0.3803051 ]\n",
      "   ...\n",
      "   [0.41087046 0.46317106 0.36426708]\n",
      "   [0.34775338 0.4048863  0.36754695]\n",
      "   [0.46769467 0.43326634 0.44497925]]\n",
      "\n",
      "  [[0.33483058 0.37920594 0.3852934 ]\n",
      "   [0.2897097  0.29644284 0.2725757 ]\n",
      "   [0.3114171  0.24902405 0.310934  ]\n",
      "   ...\n",
      "   [0.36481002 0.32245082 0.33221564]\n",
      "   [0.30020764 0.28203094 0.31480864]\n",
      "   [0.4051571  0.37949473 0.41242275]]\n",
      "\n",
      "  [[0.34129727 0.4343174  0.34929317]\n",
      "   [0.29940626 0.3281172  0.2936565 ]\n",
      "   [0.32282093 0.30124947 0.29329035]\n",
      "   ...\n",
      "   [0.32285962 0.35775635 0.29039517]\n",
      "   [0.31181258 0.35717812 0.28267565]\n",
      "   [0.43543687 0.40841058 0.40370512]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.36063403 0.39881766 0.3359801 ]\n",
      "   [0.25660664 0.2578097  0.2938921 ]\n",
      "   [0.31430107 0.27624184 0.3243368 ]\n",
      "   ...\n",
      "   [0.33568016 0.36436296 0.3269429 ]\n",
      "   [0.32939956 0.31323764 0.28795084]\n",
      "   [0.37042972 0.4275574  0.44200575]]\n",
      "\n",
      "  [[0.3197209  0.43005505 0.32530522]\n",
      "   [0.26448217 0.2719537  0.2672109 ]\n",
      "   [0.26755798 0.29670998 0.26088145]\n",
      "   ...\n",
      "   [0.31875888 0.34432393 0.306971  ]\n",
      "   [0.27038312 0.2879363  0.3321878 ]\n",
      "   [0.40357086 0.39996403 0.40512538]]\n",
      "\n",
      "  [[0.44111666 0.42360333 0.47038963]\n",
      "   [0.36679438 0.32061344 0.3884839 ]\n",
      "   [0.43701538 0.28980738 0.37683204]\n",
      "   ...\n",
      "   [0.39172682 0.34525964 0.38531938]\n",
      "   [0.41646376 0.3778394  0.36651245]\n",
      "   [0.44199392 0.37487942 0.50713754]]]]\n",
      "<class 'numpy.ndarray'>\n",
      "(4, 256, 256, 3)\n",
      "------\n",
      "[[[0.3563316  0.45519364 0.4088742 ]\n",
      "  [0.34963843 0.40177232 0.33683735]\n",
      "  [0.34500223 0.3767555  0.3653191 ]\n",
      "  ...\n",
      "  [0.32795337 0.41059804 0.32107684]\n",
      "  [0.3300417  0.37702805 0.28387484]\n",
      "  [0.43985987 0.39411676 0.43800193]]\n",
      "\n",
      " [[0.3246005  0.38955003 0.38406205]\n",
      "  [0.2873537  0.28327107 0.2830343 ]\n",
      "  [0.30425683 0.2635256  0.30795786]\n",
      "  ...\n",
      "  [0.32553145 0.25778633 0.29720494]\n",
      "  [0.27167368 0.24783893 0.25150907]\n",
      "  [0.3897106  0.34910053 0.415422  ]]\n",
      "\n",
      " [[0.3405178  0.43803388 0.31173682]\n",
      "  [0.28677326 0.31971803 0.29878166]\n",
      "  [0.3265509  0.2974176  0.30722687]\n",
      "  ...\n",
      "  [0.26082313 0.29660323 0.29376858]\n",
      "  [0.264296   0.26848808 0.22831477]\n",
      "  [0.39211643 0.3325753  0.41077384]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.36568233 0.37203336 0.32879296]\n",
      "  [0.25039956 0.27398324 0.28343955]\n",
      "  [0.2830021  0.2858105  0.3394029 ]\n",
      "  ...\n",
      "  [0.2943837  0.33171362 0.27733997]\n",
      "  [0.31851262 0.31045905 0.25006077]\n",
      "  [0.35959077 0.36701605 0.40671661]]\n",
      "\n",
      " [[0.33100018 0.4251989  0.30280828]\n",
      "  [0.2660433  0.26458073 0.2752106 ]\n",
      "  [0.3061156  0.28218958 0.27654913]\n",
      "  ...\n",
      "  [0.28478956 0.26427096 0.27697673]\n",
      "  [0.25307038 0.25294533 0.27500325]\n",
      "  [0.38984194 0.3591069  0.3889791 ]]\n",
      "\n",
      " [[0.44908625 0.41186926 0.47886032]\n",
      "  [0.36166522 0.33755744 0.40818968]\n",
      "  [0.46902618 0.30716833 0.37300876]\n",
      "  ...\n",
      "  [0.37822518 0.32377505 0.39835617]\n",
      "  [0.41651925 0.33161548 0.37027937]\n",
      "  [0.43837056 0.38042057 0.5079697 ]]]\n",
      "<class 'numpy.ndarray'>\n",
      "(256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "# train over time\n",
    "for epoch in range(n_epochs):\n",
    "    # progress bar visualization (comment out in ML Engine)\n",
    "    progbar = generic_utils.Progbar(len(train_datagen))\n",
    "    for images, points, masks in train_datagen.flow(batch_size):\n",
    "        # and the matrix of ones that we depend on in the neural net to inverse masks\n",
    "        mask_inv = np.ones((len(images), input_shape[0], input_shape[1], 1))\n",
    "        # generate the inputs (images)\n",
    "        generated_img = gen_brain.predict([images, masks, mask_inv])\n",
    "        # generate the labels\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        # the gen and disc losses\n",
    "        g_loss = 0.0\n",
    "        d_loss = 0.0\n",
    "        # ______________________\n",
    "        if epoch < tc:\n",
    "            # set the gen loss\n",
    "            g_loss = gen_brain.train_on_batch([images, points], valid)\n",
    "        # ______________________\n",
    "        else:\n",
    "            # throw in real unedited images with label VALID\n",
    "            d_loss_real = disc_brain.train_on_batch([images, points], valid)\n",
    "            # throw in A.I. generated images with label FAKE\n",
    "            d_loss_fake = disc_brain.train_on_batch([generated_img, points], fake)\n",
    "            # combine and set the disc loss\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            # ______________________\n",
    "            if epoch >= tc + td:\n",
    "                # train the entire brain\n",
    "                g_loss = brain.train_on_batch([images, masks, mask_inv, points], [images, valid])\n",
    "                # and update the generator loss\n",
    "                g_loss = g_loss[0] + alpha * g_loss[1]\n",
    "        # progress bar visualization (comment out in ML Engine)\n",
    "        progbar.add(images.shape[0], values=[(\"Disc Loss: \", d_loss), (\"Gen mse: \", g_loss)])\n",
    "        gen_img_count += 1\n",
    "        # save the generated image\n",
    "        last_img = generated_img[0]\n",
    "        last_img[:,:,0] = last_img[:,:,0]*255\n",
    "        last_img[:,:,1] = last_img[:,:,1]*255\n",
    "        last_img[:,:,2] = last_img[:,:,2]*255\n",
    "        dreamt_image = Image.fromarray(last_img.astype(int), 'RGB')\n",
    "        dreamt_image.save(f\"outputs/images/epoch_{gen_img_count}_image.png\")\n",
    "        \n",
    "gen_model.save(os.path.join(result_dir, \"generator.h5\"))\n",
    "disc_model.save(os.path.join(result_dir, \"discriminator.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# To Do List\n",
    "1. Find out when to use model.train_on_batch() vs model.fit() vs model.fit_to_generator()\n",
    "2. Find out how to save the last generated image of each epoch to Google Cloud Storage\n",
    "3. Find out how to retrieve and display the accuracy & percision metrics during training\n",
    "4. Re-write the iPython Notebook into a Python Module\n",
    "5. Setup the arguements injection for ML Engine\n",
    "6. Setup multi-GPU training on ML Engine\n",
    "7. Test on ML Engine\n",
    "8. Train fully on ML Engine\n",
    "\n",
    "9. Maybe some data augmentation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
