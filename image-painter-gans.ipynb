{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Reshape, Lambda, Flatten, Activation, Conv2D, Conv2DTranspose, Dense, Input, Subtract, Add, Multiply\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Sequential, Model\n",
    "from keras.engine.network import Network\n",
    "from keras.optimizers import Adadelta\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_generator(input_shape=(256, 256, 3)):\n",
    "    in_layer = Input(shape=input_shape)\n",
    "\n",
    "    model = Conv2D(64, kernel_size=5, strides=1, padding='same',\n",
    "                     dilation_rate=(1, 1))(in_layer)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2D(128, kernel_size=3, strides=2,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(128, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2D(256, kernel_size=3, strides=2,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(2, 2))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(4, 4))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(8, 8))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(16, 16))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2DTranspose(128, kernel_size=4, strides=2,\n",
    "                              padding='same')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(128, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2DTranspose(64, kernel_size=4, strides=2,\n",
    "                              padding='same')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(32, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "    model = Conv2D(3, kernel_size=3, strides=1,\n",
    "                     padding='same', dilation_rate=(1, 1))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('sigmoid')(model)\n",
    "    model_gen = Model(inputs=in_layer, outputs=model)\n",
    "    model_gen.name = 'Gener8tor'\n",
    "    return model_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_discriminator(global_shape=(256, 256, 3), local_shape=(128, 128, 3)):\n",
    "    def crop_image(img, crop):\n",
    "        return tf.image.crop_to_bounding_box(img,\n",
    "                                             crop[1],\n",
    "                                             crop[0],\n",
    "                                             crop[3] - crop[1],\n",
    "                                             crop[2] - crop[0])\n",
    "\n",
    "    in_pts = Input(shape=(4,), dtype='int32')\n",
    "    cropping = Lambda(lambda x: K.map_fn(lambda y: crop_image(y[0], y[1]), elems=x, dtype=tf.float32),\n",
    "                      output_shape=local_shape)\n",
    "    g_img = Input(shape=global_shape)\n",
    "    l_img = cropping([g_img, in_pts])\n",
    "\n",
    "    # Local Discriminator\n",
    "    x_l = Conv2D(64, kernel_size=5, strides=2, padding='same')(l_img)\n",
    "    x_l = BatchNormalization()(x_l)\n",
    "    x_l = Activation('relu')(x_l)\n",
    "    x_l = Conv2D(128, kernel_size=5, strides=2, padding='same')(x_l)\n",
    "    x_l = BatchNormalization()(x_l)\n",
    "    x_l = Activation('relu')(x_l)\n",
    "    x_l = Conv2D(256, kernel_size=5, strides=2, padding='same')(x_l)\n",
    "    x_l = BatchNormalization()(x_l)\n",
    "    x_l = Activation('relu')(x_l)\n",
    "    x_l = Conv2D(512, kernel_size=5, strides=2, padding='same')(x_l)\n",
    "    x_l = BatchNormalization()(x_l)\n",
    "    x_l = Activation('relu')(x_l)\n",
    "    x_l = Conv2D(512, kernel_size=5, strides=2, padding='same')(x_l)\n",
    "    x_l = BatchNormalization()(x_l)\n",
    "    x_l = Activation('relu')(x_l)\n",
    "    x_l = Flatten()(x_l)\n",
    "    x_l = Dense(1024, activation='relu')(x_l)\n",
    "\n",
    "    # Global Discriminator\n",
    "    x_g = Conv2D(64, kernel_size=5, strides=2, padding='same')(g_img)\n",
    "    x_g = BatchNormalization()(x_g)\n",
    "    x_g = Activation('relu')(x_g)\n",
    "    x_g = Conv2D(128, kernel_size=5, strides=2, padding='same')(x_g)\n",
    "    x_g = BatchNormalization()(x_g)\n",
    "    x_g = Activation('relu')(x_g)\n",
    "    x_g = Conv2D(256, kernel_size=5, strides=2, padding='same')(x_g)\n",
    "    x_g = BatchNormalization()(x_g)\n",
    "    x_g = Activation('relu')(x_g)\n",
    "    x_g = Conv2D(512, kernel_size=5, strides=2, padding='same')(x_g)\n",
    "    x_g = BatchNormalization()(x_g)\n",
    "    x_g = Activation('relu')(x_g)\n",
    "    x_g = Conv2D(512, kernel_size=5, strides=2, padding='same')(x_g)\n",
    "    x_g = BatchNormalization()(x_g)\n",
    "    x_g = Activation('relu')(x_g)\n",
    "    x_g = Conv2D(512, kernel_size=5, strides=2, padding='same')(x_g)\n",
    "    x_g = BatchNormalization()(x_g)\n",
    "    x_g = Activation('relu')(x_g)\n",
    "    x_g = Flatten()(x_g)\n",
    "    x_g = Dense(1024, activation='relu')(x_g)\n",
    "\n",
    "    x = Concatenate(axis=1)([x_l, x_g])\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model_disc = Model(inputs=[g_img, in_pts], outputs=x)\n",
    "    model_disc.name = 'Discimi-hater'\n",
    "    return model_disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_models(model, filename):\n",
    "    from keras.utils import plot_model\n",
    "    plot_model(model, to_file=filename, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_gen_layer(org_img, mask, ones):\n",
    "    from keras.layers import Concatenate\n",
    "\n",
    "    # grab the inverse mask, that only shows the masked areas\n",
    "    # 1 - mask\n",
    "    inverse_mask = Subtract()([ones, mask])\n",
    "\n",
    "    # which outputs the erased_image as input\n",
    "    # org_img * (1 - mask)\n",
    "    erased_image = Multiply()([org_img, inverse_mask])\n",
    "\n",
    "    # view our net\n",
    "    gen_model = model_generator(input_shape)\n",
    "    # print(gen_model)\n",
    "\n",
    "    # pass in the erased_image as input\n",
    "    gen_model = gen_model(erased_image)\n",
    "    # print(gen_model)\n",
    "\n",
    "    gen_brain = Model(inputs=[org_img, mask, ones], outputs=gen_model)\n",
    "    # print(gen_net)\n",
    "    view_models(gen_net, 'summaries/gen_net.png')\n",
    "\n",
    "    optimizer = Adadelta()\n",
    "    gen_brain.compile(\n",
    "        loss='mse',\n",
    "        optimizer=optimizer\n",
    "    )\n",
    "    # gen_brain.summary()\n",
    "    return gen_brain, gen_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_disc_layer(global_shape, local_shape, full_img, clip_coords):\n",
    "    # the discriminator side\n",
    "    disc_model = model_discriminator(global_shape, local_shape)\n",
    "\n",
    "    disc_model = disc_model([full_img, clip_coords])\n",
    "    disc_model\n",
    "    # print(disc_model)\n",
    "\n",
    "    disc_brain = Model(inputs=[full_img, clip_coords], outputs=disc_model)\n",
    "    disc_brain.compile(loss='binary_crossentropy',\n",
    "                        optimizer=optimizer)\n",
    "    # disc_brain.summary()\n",
    "    view_models(disc_brain, 'summaries/disc_brain.png')\n",
    "    return disc_brain, disc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.training.Model object at 0x179806400>\n",
      "<keras.engine.training.Model object at 0x17b03fd30>\n",
      "Tensor(\"Gener8tor_19/activation_939/Sigmoid:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "Tensor(\"Discimi-hater_16/dense_69/Sigmoid:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "global_shape = (256,256,3)\n",
    "local_shape = (128,128,3)\n",
    "\n",
    "full_img = Input(shape=global_shape)\n",
    "clip_img = Input(shape=local_shape)\n",
    "mask = Input(shape=(global_shape[0], global_shape[1], 1))\n",
    "ones = Input(shape=(global_shape[0], global_shape[1], 1))\n",
    "clip_coords = Input(shape=(4,), dtype='int32')\n",
    "\n",
    "gen_brain, gen_model = full_gen_layer(full_img, mask, ones)\n",
    "disc_brain, disc_model = full_disc_layer(global_shape, local_shape, full_img, clip_coords)\n",
    "\n",
    "print(gen_brain)\n",
    "print(disc_brain)\n",
    "\n",
    "print(gen_model)\n",
    "print(disc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.training.Model object at 0x176b42cc0>\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_274 (InputLayer)          (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_273 (InputLayer)          (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_271 (InputLayer)          (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "subtract_35 (Subtract)          (None, 256, 256, 1)  0           input_274[0][0]                  \n",
      "                                                                 input_273[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_35 (Multiply)          (None, 256, 256, 3)  0           input_271[0][0]                  \n",
      "                                                                 subtract_35[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Gener8tor (Model)               (None, 256, 256, 3)  6076495     multiply_35[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_275 (InputLayer)          (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Connected-Discrimi-Hater (Model (None, 1)            45070593    Gener8tor[1][0]                  \n",
      "                                                                 input_275[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 51,147,088\n",
      "Trainable params: 51,134,218\n",
      "Non-trainable params: 12,870\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.0004\n",
    "\n",
    "# the final brain\n",
    "disc_model.trainable = False\n",
    "connected_disc = Model(inputs=[full_img, clip_coords], outputs=disc_model)\n",
    "connected_disc.name = 'Connected-Discrimi-Hater'\n",
    "print(connected_disc)\n",
    "\n",
    "brain = Model(inputs=[full_img, mask, ones, clip_coords], outputs=[gen_model, connected_disc([gen_model, clip_coords])])\n",
    "brain.compile(loss=['mse', 'binary_crossentropy'],\n",
    "                      loss_weights=[1.0, alpha], optimizer=optimizer)\n",
    "brain.summary()\n",
    "view_models(brain, 'summaries/brain.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DataGenerator(object):\n",
    "    # time for data generator stuff...\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
